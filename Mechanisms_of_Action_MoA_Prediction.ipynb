{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041911,
     "end_time": "2020-11-10T19:37:40.005549",
     "exception": false,
     "start_time": "2020-11-10T19:37:39.963638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# If you like it, Do Upvote :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-10T19:37:40.092261Z",
     "iopub.status.busy": "2020-11-10T19:37:40.091572Z",
     "iopub.status.idle": "2020-11-10T19:37:40.944246Z",
     "shell.execute_reply": "2020-11-10T19:37:40.942774Z"
    },
    "papermill": {
     "duration": 0.899266,
     "end_time": "2020-11-10T19:37:40.944373",
     "exception": false,
     "start_time": "2020-11-10T19:37:40.045107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:37:41.035243Z",
     "iopub.status.busy": "2020-11-10T19:37:41.034419Z",
     "iopub.status.idle": "2020-11-10T19:38:28.143494Z",
     "shell.execute_reply": "2020-11-10T19:38:28.142528Z"
    },
    "papermill": {
     "duration": 47.157855,
     "end_time": "2020-11-10T19:38:28.143638",
     "exception": false,
     "start_time": "2020-11-10T19:37:40.985783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/titu1994/tf-TabNet.git\r\n",
      "  Cloning https://github.com/titu1994/tf-TabNet.git to /tmp/pip-req-build-2obmkq3f\r\n",
      "Building wheels for collected packages: tabnet\r\n",
      "  Building wheel for tabnet (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for tabnet: filename=tabnet-0.1.6-py2.py3-none-any.whl size=16193 sha256=206a78556b91d0770e39b40708a1ffbb64ce85f7aee41f2d4f45b5d6ff88b9ad\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1y7tkzi9/wheels/ed/f4/a5/1e028b195ef60cabf0c8324b664297f1c901990c310b54d2ed\r\n",
      "Successfully built tabnet\r\n",
      "Installing collected packages: tabnet\r\n",
      "Successfully installed tabnet-0.1.6\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Requirement already satisfied: tabnet[gpu] in /opt/conda/lib/python3.7/site-packages (0.1.6)\r\n",
      "Collecting tensorflow-gpu; extra == \"gpu\"\r\n",
      "  Downloading tensorflow_gpu-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 22 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (3.3.0)\r\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (3.13.0)\r\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.6.3)\r\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (0.10.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.11.2)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (0.34.2)\r\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (2.10.0)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (2.3.0)\r\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (0.3.3)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.14.0)\r\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.1.2)\r\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.18.5)\r\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.31.0)\r\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (2.3.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (0.2.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (2.23.0)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.7.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.14.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.0.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (3.2.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (0.4.1)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.24.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (2020.6.20)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (2.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (3.0.4)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (3.1.1)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (4.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (0.2.7)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (1.2.0)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu; extra == \"gpu\"->tabnet[gpu]) (3.0.1)\r\n",
      "Installing collected packages: tensorflow-gpu\r\n",
      "Successfully installed tensorflow-gpu-2.3.1\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.4 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/titu1994/tf-TabNet.git\n",
    "!pip install tabnet[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:38:28.973460Z",
     "iopub.status.busy": "2020-11-10T19:38:28.971207Z",
     "iopub.status.idle": "2020-11-10T19:38:28.975398Z",
     "shell.execute_reply": "2020-11-10T19:38:28.974444Z"
    },
    "papermill": {
     "duration": 0.435964,
     "end_time": "2020-11-10T19:38:28.975585",
     "exception": false,
     "start_time": "2020-11-10T19:38:28.539621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tabnet.tabnet import TabNet\n",
    "#from tabnet.tabnet import TabNetClassifier \n",
    "#from tabnet import StackedTabNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-10T19:38:29.647188Z",
     "iopub.status.busy": "2020-11-10T19:38:29.645728Z",
     "iopub.status.idle": "2020-11-10T19:38:32.739791Z",
     "shell.execute_reply": "2020-11-10T19:38:32.748148Z"
    },
    "papermill": {
     "duration": 3.429334,
     "end_time": "2020-11-10T19:38:32.748335",
     "exception": false,
     "start_time": "2020-11-10T19:38:29.319001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FactorAnalysis, FastICA, TruncatedSVD\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential,load_model,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input,LeakyReLU,BatchNormalization,MaxPool2D,Concatenate,Conv2D,Reshape\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:38:33.140501Z",
     "iopub.status.busy": "2020-11-10T19:38:33.139510Z",
     "iopub.status.idle": "2020-11-10T19:38:33.147405Z",
     "shell.execute_reply": "2020-11-10T19:38:33.147895Z"
    },
    "papermill": {
     "duration": 0.202153,
     "end_time": "2020-11-10T19:38:33.148038",
     "exception": false,
     "start_time": "2020-11-10T19:38:32.945885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'train_drug.csv',\n",
       " 'train_targets_scored.csv',\n",
       " 'train_targets_nonscored.csv',\n",
       " 'train_features.csv',\n",
       " 'test_features.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../input/lish-moa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:38:33.537881Z",
     "iopub.status.busy": "2020-11-10T19:38:33.536730Z",
     "iopub.status.idle": "2020-11-10T19:38:41.259700Z",
     "shell.execute_reply": "2020-11-10T19:38:41.258665Z"
    },
    "papermill": {
     "duration": 7.921082,
     "end_time": "2020-11-10T19:38:41.259814",
     "exception": false,
     "start_time": "2020-11-10T19:38:33.338732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets_scored = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv('../input/lish-moa/train_targets_nonscored.csv')\n",
    "\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "sample_submission = pd.read_csv('../input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:38:41.644883Z",
     "iopub.status.busy": "2020-11-10T19:38:41.640533Z",
     "iopub.status.idle": "2020-11-10T19:38:41.646999Z",
     "shell.execute_reply": "2020-11-10T19:38:41.647478Z"
    },
    "papermill": {
     "duration": 0.202947,
     "end_time": "2020-11-10T19:38:41.647612",
     "exception": false,
     "start_time": "2020-11-10T19:38:41.444665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "Others = [col for col in train_features.columns if (col not in GENES) and (col not in CELLS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:38:42.033122Z",
     "iopub.status.busy": "2020-11-10T19:38:42.032072Z",
     "iopub.status.idle": "2020-11-10T19:38:51.771415Z",
     "shell.execute_reply": "2020-11-10T19:38:51.770437Z"
    },
    "papermill": {
     "duration": 9.931029,
     "end_time": "2020-11-10T19:38:51.771536",
     "exception": false,
     "start_time": "2020-11-10T19:38:41.840507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "for col in (GENES + CELLS):\n",
    "\n",
    "    transformer = QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\")\n",
    "    vec_len = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    raw_vec = train_features[col].values.reshape(vec_len, 1)\n",
    "    transformer.fit(raw_vec)\n",
    "\n",
    "    train_features[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "    test_features[col] = transformer.transform(test_features[col].values.reshape(vec_len_test, 1)).reshape(1, vec_len_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:38:52.141260Z",
     "iopub.status.busy": "2020-11-10T19:38:52.140465Z",
     "iopub.status.idle": "2020-11-10T19:38:52.143951Z",
     "shell.execute_reply": "2020-11-10T19:38:52.143458Z"
    },
    "papermill": {
     "duration": 0.190413,
     "end_time": "2020-11-10T19:38:52.144056",
     "exception": false,
     "start_time": "2020-11-10T19:38:51.953643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:38:52.524795Z",
     "iopub.status.busy": "2020-11-10T19:38:52.523551Z",
     "iopub.status.idle": "2020-11-10T19:38:52.679000Z",
     "shell.execute_reply": "2020-11-10T19:38:52.678452Z"
    },
    "papermill": {
     "duration": 0.352288,
     "end_time": "2020-11-10T19:38:52.679106",
     "exception": false,
     "start_time": "2020-11-10T19:38:52.326818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "atp-sensitive_potassium_channel_antagonist      1\n",
       "erbb2_inhibitor                                 1\n",
       "diuretic                                        6\n",
       "autotaxin_inhibitor                             6\n",
       "protein_phosphatase_inhibitor                   6\n",
       "                                             ... \n",
       "serotonin_receptor_antagonist                 404\n",
       "dopamine_receptor_antagonist                  424\n",
       "cyclooxygenase_inhibitor                      435\n",
       "proteasome_inhibitor                          726\n",
       "nfkb_inhibitor                                832\n",
       "Length: 206, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_scored.sum()[1:].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:38:53.045149Z",
     "iopub.status.busy": "2020-11-10T19:38:53.044469Z",
     "iopub.status.idle": "2020-11-10T19:38:53.052149Z",
     "shell.execute_reply": "2020-11-10T19:38:53.052683Z"
    },
    "papermill": {
     "duration": 0.195476,
     "end_time": "2020-11-10T19:38:53.052808",
     "exception": false,
     "start_time": "2020-11-10T19:38:52.857332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['trt_cp', 'ctl_vehicle'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features['cp_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.18759,
     "end_time": "2020-11-10T19:38:53.424257",
     "exception": false,
     "start_time": "2020-11-10T19:38:53.236667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PCA features + Existing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:38:53.804571Z",
     "iopub.status.busy": "2020-11-10T19:38:53.803831Z",
     "iopub.status.idle": "2020-11-10T19:39:10.776590Z",
     "shell.execute_reply": "2020-11-10T19:39:10.775676Z"
    },
    "papermill": {
     "duration": 17.170855,
     "end_time": "2020-11-10T19:39:10.776704",
     "exception": false,
     "start_time": "2020-11-10T19:38:53.605849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GENES\n",
    "n_comp = 600  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (TruncatedSVD(n_components=n_comp, n_iter=7, random_state=42).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)\n",
    "\n",
    "#data2 = (TruncatedSVD(n_components=n_comp, n_iter=7, random_state=42).fit_transform(data[GENES]))\n",
    "#train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "#train2 = pd.DataFrame(train2, columns=[f'svd_G-{i}' for i in range(n_comp)])\n",
    "#test2 = pd.DataFrame(test2, columns=[f'svd_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "#train_features = pd.concat((train_features, train2), axis=1)\n",
    "#test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:39:11.154787Z",
     "iopub.status.busy": "2020-11-10T19:39:11.153515Z",
     "iopub.status.idle": "2020-11-10T19:39:12.002721Z",
     "shell.execute_reply": "2020-11-10T19:39:12.002173Z"
    },
    "papermill": {
     "duration": 1.042814,
     "end_time": "2020-11-10T19:39:12.002826",
     "exception": false,
     "start_time": "2020-11-10T19:39:10.960012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELLS\n",
    "n_comp = 50  #<--Update\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (TruncatedSVD(n_components=n_comp, n_iter=7, random_state=42).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)\n",
    "\n",
    "#data2 = (TruncatedSVD(n_components=n_comp, n_iter=7, random_state=42).fit_transform(data[CELLS]))\n",
    "#train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "#train2 = pd.DataFrame(train2, columns=[f'fa_C-{i}' for i in range(n_comp)])\n",
    "#test2 = pd.DataFrame(test2, columns=[f'fa_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "#train_features = pd.concat((train_features, train2), axis=1)\n",
    "#test_features = pd.concat((test_features, test2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:39:12.452600Z",
     "iopub.status.busy": "2020-11-10T19:39:12.451427Z",
     "iopub.status.idle": "2020-11-10T19:39:12.461116Z",
     "shell.execute_reply": "2020-11-10T19:39:12.454140Z"
    },
    "papermill": {
     "duration": 0.260835,
     "end_time": "2020-11-10T19:39:12.461279",
     "exception": false,
     "start_time": "2020-11-10T19:39:12.200444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 1526)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.291314,
     "end_time": "2020-11-10T19:39:13.041545",
     "exception": false,
     "start_time": "2020-11-10T19:39:12.750231",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# feature Selection using Variance Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:39:13.582223Z",
     "iopub.status.busy": "2020-11-10T19:39:13.581325Z",
     "iopub.status.idle": "2020-11-10T19:39:14.656017Z",
     "shell.execute_reply": "2020-11-10T19:39:14.655418Z"
    },
    "papermill": {
     "duration": 1.352569,
     "end_time": "2020-11-10T19:39:14.656124",
     "exception": false,
     "start_time": "2020-11-10T19:39:13.303555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 1040)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "var_thresh = VarianceThreshold(0.8)  #<-- Update\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thresh.fit_transform(data.iloc[:, 4:])\n",
    "\n",
    "train_features_transformed = data_transformed[ : train_features.shape[0]]\n",
    "test_features_transformed = data_transformed[-test_features.shape[0] : ]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                              columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']].values.reshape(-1, 4),\\\n",
    "                             columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:39:15.035150Z",
     "iopub.status.busy": "2020-11-10T19:39:15.034317Z",
     "iopub.status.idle": "2020-11-10T19:40:27.513050Z",
     "shell.execute_reply": "2020-11-10T19:40:27.514166Z"
    },
    "papermill": {
     "duration": 72.67612,
     "end_time": "2020-11-10T19:40:27.514338",
     "exception": false,
     "start_time": "2020-11-10T19:39:14.838218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def fe_cluster(train, test, n_clusters_g = 35, n_clusters_c = 5, SEED = 123):\n",
    "    \n",
    "    features_g = list(train.columns[4:776])\n",
    "    features_c = list(train.columns[776:876])\n",
    "    \n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans = KMeans(n_clusters = n_clusters, random_state = SEED).fit(data)\n",
    "        train[f'clusters_{kind}'] = kmeans.labels_[:train.shape[0]]\n",
    "        test[f'clusters_{kind}'] = kmeans.labels_[train.shape[0]:]\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "train_features_ ,test_features_ =fe_cluster(train_features,test_features)\n",
    "#train_features = pd.concat((train_features, train_features_), axis=1)\n",
    "#test_features = pd.concat((test_features, test_features_), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:27.901730Z",
     "iopub.status.busy": "2020-11-10T19:40:27.900259Z",
     "iopub.status.idle": "2020-11-10T19:40:33.416347Z",
     "shell.execute_reply": "2020-11-10T19:40:33.415735Z"
    },
    "papermill": {
     "duration": 5.714317,
     "end_time": "2020-11-10T19:40:33.416461",
     "exception": false,
     "start_time": "2020-11-10T19:40:27.702144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fe_stats(train, test):\n",
    "    \n",
    "    features_g = list(train.columns[4:776])\n",
    "    features_c = list(train.columns[776:876])\n",
    "    \n",
    "    for df in train, test:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "        \n",
    "    return train, test\n",
    "\n",
    "train_features,test_features=fe_stats(train_features,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:33.815299Z",
     "iopub.status.busy": "2020-11-10T19:40:33.813838Z",
     "iopub.status.idle": "2020-11-10T19:40:34.383921Z",
     "shell.execute_reply": "2020-11-10T19:40:34.383390Z"
    },
    "papermill": {
     "duration": 0.775922,
     "end_time": "2020-11-10T19:40:34.384052",
     "exception": false,
     "start_time": "2020-11-10T19:40:33.608130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[train_targets_scored.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:34.824091Z",
     "iopub.status.busy": "2020-11-10T19:40:34.817681Z",
     "iopub.status.idle": "2020-11-10T19:40:34.827505Z",
     "shell.execute_reply": "2020-11-10T19:40:34.826991Z"
    },
    "papermill": {
     "duration": 0.263463,
     "end_time": "2020-11-10T19:40:34.827607",
     "exception": false,
     "start_time": "2020-11-10T19:40:34.564144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:35.191652Z",
     "iopub.status.busy": "2020-11-10T19:40:35.190729Z",
     "iopub.status.idle": "2020-11-10T19:40:35.228896Z",
     "shell.execute_reply": "2020-11-10T19:40:35.229449Z"
    },
    "papermill": {
     "duration": 0.224022,
     "end_time": "2020-11-10T19:40:35.229590",
     "exception": false,
     "start_time": "2020-11-10T19:40:35.005568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>-1.364787</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>0.313396</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>0.235577</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>-2.288417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>-0.375501</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.237856</td>\n",
       "      <td>-1.228203</td>\n",
       "      <td>0.218376</td>\n",
       "      <td>-0.365976</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>0.569243</td>\n",
       "      <td>-0.150978</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>0.735603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>-0.304313</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>-1.622462</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  1.134849  0.907687 -0.416385 -0.966814   \n",
       "1      id_000779bfc      72      D1  0.119282  0.681738  0.272399  0.080113   \n",
       "2      id_000a6266a      48      D1  0.779973  0.946463  1.425350 -0.132928   \n",
       "3      id_0015fd391      48      D1 -0.734910 -0.274641 -0.438509  0.759097   \n",
       "4      id_001626bd3      72      D2 -0.452718 -0.477513  0.972316  0.970731   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1  0.237856 -1.228203  0.218376 -0.365976   \n",
       "21944  id_fffb1ceed      24      D2  0.209361 -0.022389 -0.235888 -0.796989   \n",
       "21945  id_fffb70c0c      24      D2 -1.911021  0.587228 -0.588417  1.296405   \n",
       "21946  id_fffcb9e7c      24      D1  0.816407  0.417618  0.431631  0.300617   \n",
       "21947  id_ffffdd77b      72      D1 -1.243096  1.567730 -0.269573  1.083636   \n",
       "\n",
       "              4         5         6  ...  \\\n",
       "0     -0.254723 -1.017473 -1.364787  ...   \n",
       "1      1.205169  0.686517  0.313396  ...   \n",
       "2     -0.006122  1.492493  0.235577  ...   \n",
       "3      2.346330 -0.858153 -2.288417  ...   \n",
       "4      1.463427 -0.869555 -0.375501  ...   \n",
       "...         ...       ...       ...  ...   \n",
       "21943 -0.330177  0.569243 -0.150978  ...   \n",
       "21944 -0.674009  0.919312  0.735603  ...   \n",
       "21945 -1.002640  0.850589 -0.304313  ...   \n",
       "21946  1.070346 -0.024189  0.048942  ...   \n",
       "21947 -0.511235 -2.099634 -1.622462  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "0                                          0             0                0   \n",
       "1                                          0             0                0   \n",
       "2                                          0             0                0   \n",
       "3                                          0             0                0   \n",
       "4                                          0             0                0   \n",
       "...                                      ...           ...              ...   \n",
       "21943                                      0             0                0   \n",
       "21944                                      0             0                0   \n",
       "21945                                      0             0                0   \n",
       "21946                                      0             0                0   \n",
       "21947                                      0             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                               0              0  \n",
       "1                               0              0  \n",
       "2                               0              0  \n",
       "3                               0              0  \n",
       "4                               0              0  \n",
       "...                           ...            ...  \n",
       "21943                           0              0  \n",
       "21944                           0              0  \n",
       "21945                           0              0  \n",
       "21946                           0              0  \n",
       "21947                           0              0  \n",
       "\n",
       "[21948 rows x 1261 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:35.612426Z",
     "iopub.status.busy": "2020-11-10T19:40:35.611524Z",
     "iopub.status.idle": "2020-11-10T19:40:35.614591Z",
     "shell.execute_reply": "2020-11-10T19:40:35.614121Z"
    },
    "papermill": {
     "duration": 0.197361,
     "end_time": "2020-11-10T19:40:35.614696",
     "exception": false,
     "start_time": "2020-11-10T19:40:35.417335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.184903,
     "end_time": "2020-11-10T19:40:35.985457",
     "exception": false,
     "start_time": "2020-11-10T19:40:35.800554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:36.362087Z",
     "iopub.status.busy": "2020-11-10T19:40:36.360824Z",
     "iopub.status.idle": "2020-11-10T19:40:39.550945Z",
     "shell.execute_reply": "2020-11-10T19:40:39.550378Z"
    },
    "papermill": {
     "duration": 3.381962,
     "end_time": "2020-11-10T19:40:39.551056",
     "exception": false,
     "start_time": "2020-11-10T19:40:36.169094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134849</td>\n",
       "      <td>0.907687</td>\n",
       "      <td>-0.416385</td>\n",
       "      <td>-0.966814</td>\n",
       "      <td>-0.254723</td>\n",
       "      <td>-1.017473</td>\n",
       "      <td>-1.364787</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119282</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.272399</td>\n",
       "      <td>0.080113</td>\n",
       "      <td>1.205169</td>\n",
       "      <td>0.686517</td>\n",
       "      <td>0.313396</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779973</td>\n",
       "      <td>0.946463</td>\n",
       "      <td>1.425350</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>-0.006122</td>\n",
       "      <td>1.492493</td>\n",
       "      <td>0.235577</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734910</td>\n",
       "      <td>-0.274641</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>2.346330</td>\n",
       "      <td>-0.858153</td>\n",
       "      <td>-2.288417</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452718</td>\n",
       "      <td>-0.477513</td>\n",
       "      <td>0.972316</td>\n",
       "      <td>0.970731</td>\n",
       "      <td>1.463427</td>\n",
       "      <td>-0.869555</td>\n",
       "      <td>-0.375501</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21943</th>\n",
       "      <td>id_fff8c2444</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.237856</td>\n",
       "      <td>-1.228203</td>\n",
       "      <td>0.218376</td>\n",
       "      <td>-0.365976</td>\n",
       "      <td>-0.330177</td>\n",
       "      <td>0.569243</td>\n",
       "      <td>-0.150978</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21944</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>-0.022389</td>\n",
       "      <td>-0.235888</td>\n",
       "      <td>-0.796989</td>\n",
       "      <td>-0.674009</td>\n",
       "      <td>0.919312</td>\n",
       "      <td>0.735603</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21945</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>24</td>\n",
       "      <td>D2</td>\n",
       "      <td>-1.911021</td>\n",
       "      <td>0.587228</td>\n",
       "      <td>-0.588417</td>\n",
       "      <td>1.296405</td>\n",
       "      <td>-1.002640</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>-0.304313</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21946</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.816407</td>\n",
       "      <td>0.417618</td>\n",
       "      <td>0.431631</td>\n",
       "      <td>0.300617</td>\n",
       "      <td>1.070346</td>\n",
       "      <td>-0.024189</td>\n",
       "      <td>0.048942</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21947</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>-1.243096</td>\n",
       "      <td>1.567730</td>\n",
       "      <td>-0.269573</td>\n",
       "      <td>1.083636</td>\n",
       "      <td>-0.511235</td>\n",
       "      <td>-2.099634</td>\n",
       "      <td>-1.622462</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21948 rows × 1262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0      id_000644bb2      24      D1  1.134849  0.907687 -0.416385 -0.966814   \n",
       "1      id_000779bfc      72      D1  0.119282  0.681738  0.272399  0.080113   \n",
       "2      id_000a6266a      48      D1  0.779973  0.946463  1.425350 -0.132928   \n",
       "3      id_0015fd391      48      D1 -0.734910 -0.274641 -0.438509  0.759097   \n",
       "4      id_001626bd3      72      D2 -0.452718 -0.477513  0.972316  0.970731   \n",
       "...             ...     ...     ...       ...       ...       ...       ...   \n",
       "21943  id_fff8c2444      72      D1  0.237856 -1.228203  0.218376 -0.365976   \n",
       "21944  id_fffb1ceed      24      D2  0.209361 -0.022389 -0.235888 -0.796989   \n",
       "21945  id_fffb70c0c      24      D2 -1.911021  0.587228 -0.588417  1.296405   \n",
       "21946  id_fffcb9e7c      24      D1  0.816407  0.417618  0.431631  0.300617   \n",
       "21947  id_ffffdd77b      72      D1 -1.243096  1.567730 -0.269573  1.083636   \n",
       "\n",
       "              4         5         6  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0     -0.254723 -1.017473 -1.364787  ...             0                0   \n",
       "1      1.205169  0.686517  0.313396  ...             0                0   \n",
       "2     -0.006122  1.492493  0.235577  ...             0                0   \n",
       "3      2.346330 -0.858153 -2.288417  ...             0                0   \n",
       "4      1.463427 -0.869555 -0.375501  ...             0                0   \n",
       "...         ...       ...       ...  ...           ...              ...   \n",
       "21943 -0.330177  0.569243 -0.150978  ...             0                0   \n",
       "21944 -0.674009  0.919312  0.735603  ...             0                0   \n",
       "21945 -1.002640  0.850589 -0.304313  ...             0                0   \n",
       "21946  1.070346 -0.024189  0.048942  ...             0                0   \n",
       "21947 -0.511235 -2.099634 -1.622462  ...             0                0   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0                      0                          0   \n",
       "1                      0                          0   \n",
       "2                      0                          0   \n",
       "3                      0                          0   \n",
       "4                      0                          0   \n",
       "...                  ...                        ...   \n",
       "21943                  0                          0   \n",
       "21944                  0                          0   \n",
       "21945                  0                          0   \n",
       "21946                  0                          0   \n",
       "21947                  0                          0   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                                          0                0          0   \n",
       "1                                          0                0          0   \n",
       "2                                          0                0          0   \n",
       "3                                          0                0          0   \n",
       "4                                          0                0          0   \n",
       "...                                      ...              ...        ...   \n",
       "21943                                      0                0          0   \n",
       "21944                                      0                0          0   \n",
       "21945                                      0                0          0   \n",
       "21946                                      0                0          0   \n",
       "21947                                      0                0          0   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  kfold  \n",
       "0                               0              0      0  \n",
       "1                               0              0      2  \n",
       "2                               0              0      1  \n",
       "3                               0              0      2  \n",
       "4                               0              0      2  \n",
       "...                           ...            ...    ...  \n",
       "21943                           0              0      0  \n",
       "21944                           0              0      4  \n",
       "21945                           0              0      0  \n",
       "21946                           0              0      1  \n",
       "21947                           0              0      2  \n",
       "\n",
       "[21948 rows x 1262 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = train.copy()\n",
    "\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5)\n",
    "\n",
    "for f, (t_idx, v_idx) in enumerate(mskf.split(X=train, y=target)):\n",
    "    folds.loc[v_idx, 'kfold'] = int(f)\n",
    "\n",
    "folds['kfold'] = folds['kfold'].astype(int)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:39.971302Z",
     "iopub.status.busy": "2020-11-10T19:40:39.970386Z",
     "iopub.status.idle": "2020-11-10T19:40:39.976007Z",
     "shell.execute_reply": "2020-11-10T19:40:39.976826Z"
    },
    "papermill": {
     "duration": 0.229902,
     "end_time": "2020-11-10T19:40:39.977029",
     "exception": false,
     "start_time": "2020-11-10T19:40:39.747127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1261)\n",
      "(21948, 1262)\n",
      "(3624, 1055)\n",
      "(21948, 207)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(folds.shape)\n",
    "print(test.shape)\n",
    "print(target.shape)\n",
    "print(sample_submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.184461,
     "end_time": "2020-11-10T19:40:40.353749",
     "exception": false,
     "start_time": "2020-11-10T19:40:40.169288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:40.927424Z",
     "iopub.status.busy": "2020-11-10T19:40:40.926519Z",
     "iopub.status.idle": "2020-11-10T19:40:40.931074Z",
     "shell.execute_reply": "2020-11-10T19:40:40.932712Z"
    },
    "papermill": {
     "duration": 0.319211,
     "end_time": "2020-11-10T19:40:40.932907",
     "exception": false,
     "start_time": "2020-11-10T19:40:40.613696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=4000, s=True):\n",
    "  # This is a small dataset, only load it once, and keep it in memory.\n",
    "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "  # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "    if s:\n",
    "        ds = ds.shuffle(buffer_size=shuffle_buffer_size,seed=42,reshuffle_each_iteration=True)\n",
    "\n",
    "  # Repeat forever\n",
    "  #ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:41.546381Z",
     "iopub.status.busy": "2020-11-10T19:40:41.545508Z",
     "iopub.status.idle": "2020-11-10T19:40:41.553434Z",
     "shell.execute_reply": "2020-11-10T19:40:41.554413Z"
    },
    "papermill": {
     "duration": 0.315852,
     "end_time": "2020-11-10T19:40:41.554586",
     "exception": false,
     "start_time": "2020-11-10T19:40:41.238734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "def data_load2(train,y,test,y_val):\n",
    "    label_train = np.array(y.iloc[:].values)\n",
    "    if len(y_val) == 0:\n",
    "        label_test = np.zeros((len(test),len(y.columns)))\n",
    "    else:\n",
    "        label_test = np.array(y_val.iloc[:].values)\n",
    "\n",
    "    csv_ds_train = tf.data.Dataset.from_tensor_slices(np.array(train))\n",
    "    label_ds_train = tf.data.Dataset.from_tensor_slices(label_train)\n",
    "    train_label_ds = tf.data.Dataset.zip((csv_ds_train, label_ds_train))\n",
    "\n",
    "    csv_ds_test = tf.data.Dataset.from_tensor_slices(np.array(test))\n",
    "    label_ds_test = tf.data.Dataset.from_tensor_slices(label_test)\n",
    "    test_label_ds = tf.data.Dataset.zip((csv_ds_test, label_ds_test))\n",
    "\n",
    "    train_ds = prepare_for_training(train_label_ds,s=True)\n",
    "    test_ds = prepare_for_training(test_label_ds,s=False)\n",
    "    return train_ds,test_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.181006,
     "end_time": "2020-11-10T19:40:42.013064",
     "exception": false,
     "start_time": "2020-11-10T19:40:41.832058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:42.420019Z",
     "iopub.status.busy": "2020-11-10T19:40:42.419283Z",
     "iopub.status.idle": "2020-11-10T19:40:42.422785Z",
     "shell.execute_reply": "2020-11-10T19:40:42.422267Z"
    },
    "papermill": {
     "duration": 0.22522,
     "end_time": "2020-11-10T19:40:42.422891",
     "exception": false,
     "start_time": "2020-11-10T19:40:42.197671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "initializer = tf.keras.initializers.GlorotNormal()\n",
    "def creat_model2(num_features, num_targets):\n",
    "    \n",
    "    input_csv0 = Input(shape=(num_features,))\n",
    "    input_csv = BatchNormalization()(input_csv0)\n",
    "\n",
    "    input_csv = Dropout(0.2)(input_csv)\n",
    "\n",
    "    \n",
    "    x = tfa.layers.WeightNormalization(Dense(6144,activation='relu'))(input_csv)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = tfa.layers.WeightNormalization(Dense(6144,activation='relu'))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    x0 = tfa.layers.WeightNormalization(Dense(2048,activation='relu'))(input_csv)\n",
    "    x0 = BatchNormalization()(x0)\n",
    "    x0 = Dropout(0.4)(x0)\n",
    "    x0 = tfa.layers.WeightNormalization(Dense(2048,activation='relu'))(x0)\n",
    "    x0 = BatchNormalization()(x0)\n",
    "    x0 = Dropout(0.4)(x0)\n",
    "    \n",
    "    x1 = tfa.layers.WeightNormalization(Dense(1024,activation='relu'))(input_csv)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Dropout(0.4)(x1)\n",
    "    x1 = tfa.layers.WeightNormalization(Dense(1024,activation='relu'))(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Dropout(0.4)(x1)\n",
    "\n",
    "    #x2 = tfa.layers.WeightNormalization(Dense(512,activation='relu'))(input_csv)\n",
    "    #x2 = BatchNormalization()(x2)\n",
    "    #x2 = Dropout(0.3)(x2)\n",
    "    #x2 = tfa.layers.WeightNormalization(Dense(512,activation='relu'))(x2)\n",
    "    #x2 = BatchNormalization()(x2)\n",
    "    #x2 = Dropout(0.3)(x2)\n",
    "\n",
    "    x2x =  Concatenate(axis=-1)([x,x0,x1])\n",
    "\n",
    "    pred1 = tfa.layers.WeightNormalization(Dense(num_targets,activation='softmax'))(x)\n",
    "    pred1 = BatchNormalization()(pred1)\n",
    "    #pred1 = Dropout(0.3)(pred1)\n",
    "    \n",
    "    pred0 = tfa.layers.WeightNormalization(Dense(num_targets,activation='softmax'))(x0)\n",
    "    pred0 = BatchNormalization()(pred0)\n",
    "    \n",
    "    pred2 = tfa.layers.WeightNormalization(Dense(num_targets,activation='softmax'))(x1)\n",
    "    pred2 = BatchNormalization()(pred2)\n",
    "    #pred2 = Dropout(0.3)(pred2)\n",
    "    \n",
    "    #pred3 = tfa.layers.WeightNormalization(Dense(num_targets,activation='softmax'))(x2)\n",
    "    #pred3 = BatchNormalization()(pred3)\n",
    "    #pred3 = Dropout(0.3)(pred3)\n",
    "    \n",
    "    pred4 = tfa.layers.WeightNormalization(Dense(num_targets,activation='softmax'))(x2x)\n",
    "    pred4 = BatchNormalization()(pred4)\n",
    "    #pred4 = Dropout(0.3)(pred4)\n",
    "    \n",
    "    pred = Concatenate(axis=-1)([pred1,pred0, pred2, pred4])\n",
    "    \n",
    "    se = tfa.layers.WeightNormalization(Dense(num_targets,activation='relu'))(pred)\n",
    "    se =  BatchNormalization()(se)\n",
    "    se_h = tfa.layers.WeightNormalization(Dense(num_targets))(se)\n",
    "    se_h_ = tf.keras.layers.Activation('sigmoid',name='W_h')(se_h)\n",
    "    \n",
    "    se_h = tf.keras.layers.Activation('softmax')(se_h_)\n",
    "    se_h = Dropout(0.4)(se_h)\n",
    "    pred = Dropout(0.4)(pred)\n",
    "    pred = Concatenate(axis=-1)([pred,se_h])\n",
    "    \n",
    "    se = tfa.layers.WeightNormalization(Dense(num_targets,activation='relu'))(pred)\n",
    "    se =  BatchNormalization()(se)\n",
    "    se = tfa.layers.WeightNormalization(Dense(num_targets,activation='sigmoid'),name='W_o')(se)\n",
    "    \n",
    "    model = Model(input_csv0,[se,se_h_])\n",
    "    return model\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.187899,
     "end_time": "2020-11-10T19:40:42.797205",
     "exception": false,
     "start_time": "2020-11-10T19:40:42.609306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:43.199703Z",
     "iopub.status.busy": "2020-11-10T19:40:43.197630Z",
     "iopub.status.idle": "2020-11-10T19:40:43.200426Z",
     "shell.execute_reply": "2020-11-10T19:40:43.200995Z"
    },
    "papermill": {
     "duration": 0.197423,
     "end_time": "2020-11-10T19:40:43.201135",
     "exception": false,
     "start_time": "2020-11-10T19:40:43.003712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "#     data.loc[:, 'cp_time'] = data.loc[:, 'cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "#     data.loc[:, 'cp_dose'] = data.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "\n",
    "# --------------------- Normalize ---------------------\n",
    "#    for col in data.columns[1:-5].to_list():\n",
    "#        data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#     for col in CELLS:\n",
    "#         data[col] = (data[col]-np.mean(data[col])) / (np.std(data[col]))\n",
    "    \n",
    "#--------------------- Removing Skewness ---------------------\n",
    "#    for col in data.columns[1:-5].to_list():\n",
    "#        if(abs(data[col].skew()) > 0.75):\n",
    "#            if(data[col].skew() < 0): # neg-skewness\n",
    "#                data[col] = data[col].max() - data[col] + 1\n",
    "#                data[col] = np.sqrt(data[col])\n",
    "#            \n",
    "#            else:\n",
    "#                data[col] = np.sqrt(data[col])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:43.705115Z",
     "iopub.status.busy": "2020-11-10T19:40:43.703671Z",
     "iopub.status.idle": "2020-11-10T19:40:43.893736Z",
     "shell.execute_reply": "2020-11-10T19:40:43.894471Z"
    },
    "papermill": {
     "duration": 0.446313,
     "end_time": "2020-11-10T19:40:43.894611",
     "exception": false,
     "start_time": "2020-11-10T19:40:43.448298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(folds).columns if c not in target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold','sig_id']]\n",
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:44.274433Z",
     "iopub.status.busy": "2020-11-10T19:40:44.273610Z",
     "iopub.status.idle": "2020-11-10T19:40:44.278098Z",
     "shell.execute_reply": "2020-11-10T19:40:44.277582Z"
    },
    "papermill": {
     "duration": 0.201119,
     "end_time": "2020-11-10T19:40:44.278204",
     "exception": false,
     "start_time": "2020-11-10T19:40:44.077085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "num_features=len(feature_cols)\n",
    "num_targets=len(target_cols)\n",
    "hidden_size=[6144, 2048, 1024]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.299452,
     "end_time": "2020-11-10T19:40:44.815898",
     "exception": false,
     "start_time": "2020-11-10T19:40:44.516446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Tabnet ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:45.375824Z",
     "iopub.status.busy": "2020-11-10T19:40:45.364129Z",
     "iopub.status.idle": "2020-11-10T19:40:45.399547Z",
     "shell.execute_reply": "2020-11-10T19:40:45.398967Z"
    },
    "papermill": {
     "duration": 0.255746,
     "end_time": "2020-11-10T19:40:45.399656",
     "exception": false,
     "start_time": "2020-11-10T19:40:45.143910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabnet.custom_objects import glu, sparsemax, GroupNormalization\n",
    "class TransformBlock(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, features,\n",
    "                 norm_type,\n",
    "                 momentum=0.9,\n",
    "                 virtual_batch_size=None,\n",
    "                 groups=2,\n",
    "                 block_name='',\n",
    "                 **kwargs):\n",
    "        super(TransformBlock, self).__init__(**kwargs)\n",
    "\n",
    "        self.features = features\n",
    "        self.norm_type = norm_type\n",
    "        self.momentum = momentum\n",
    "        self.groups = groups\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "\n",
    "        self.transform = tfa.layers.WeightNormalization(tf.keras.layers.Dense(self.features, use_bias=False), name=f'transformblock_dense_{block_name}')\n",
    "        self.Dropout = Dropout(0.5)\n",
    "        if norm_type == 'batch':\n",
    "            self.bn = tf.keras.layers.BatchNormalization(axis=-1, momentum=momentum,\n",
    "                                                         virtual_batch_size=virtual_batch_size,\n",
    "                                                         name=f'transformblock_bn_{block_name}')\n",
    "\n",
    "        else:\n",
    "            self.bn = GroupNormalization(axis=-1, groups=self.groups, name=f'transformblock_gn_{block_name}')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.transform(inputs)\n",
    "        x = self.Dropout(self.bn(x, training=training))\n",
    "        return x\n",
    "\n",
    "\n",
    "class TabNet(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, feature_columns,\n",
    "                 feature_dim=64,\n",
    "                 output_dim=64,\n",
    "                 num_features=None,\n",
    "                 num_decision_steps=5,\n",
    "                 relaxation_factor=1.5,\n",
    "                 sparsity_coefficient=1e-5,\n",
    "                 norm_type='group',\n",
    "                 batch_momentum=0.98,\n",
    "                 virtual_batch_size=None,\n",
    "                 num_groups=2,\n",
    "                 epsilon=1e-5,\n",
    "                 **kwargs):\n",
    "\n",
    "        super(TabNet, self).__init__(**kwargs)\n",
    "\n",
    "        # Input checks\n",
    "        if feature_columns is not None:\n",
    "            if type(feature_columns) not in (list, tuple):\n",
    "                raise ValueError(\"`feature_columns` must be a list or a tuple.\")\n",
    "\n",
    "            if len(feature_columns) == 0:\n",
    "                raise ValueError(\"`feature_columns` must be contain at least 1 tf.feature_column !\")\n",
    "\n",
    "            if num_features is None:\n",
    "                num_features = len(feature_columns)\n",
    "            else:\n",
    "                num_features = int(num_features)\n",
    "\n",
    "        else:\n",
    "            if num_features is None:\n",
    "                raise ValueError(\"If `feature_columns` is None, then `num_features` cannot be None.\")\n",
    "\n",
    "        if num_decision_steps < 1:\n",
    "            raise ValueError(\"Num decision steps must be greater than 0.\")\n",
    "\n",
    "        if feature_dim <= output_dim:\n",
    "            raise ValueError(\"To compute `features_for_coef`, feature_dim must be larger than output dim\")\n",
    "\n",
    "        feature_dim = int(feature_dim)\n",
    "        output_dim = int(output_dim)\n",
    "        num_decision_steps = int(num_decision_steps)\n",
    "        relaxation_factor = float(relaxation_factor)\n",
    "        sparsity_coefficient = float(sparsity_coefficient)\n",
    "        batch_momentum = float(batch_momentum)\n",
    "        num_groups = max(1, int(num_groups))\n",
    "        epsilon = float(epsilon)\n",
    "\n",
    "        if relaxation_factor < 0.:\n",
    "            raise ValueError(\"`relaxation_factor` cannot be negative !\")\n",
    "\n",
    "        if sparsity_coefficient < 0.:\n",
    "            raise ValueError(\"`sparsity_coefficient` cannot be negative !\")\n",
    "\n",
    "        if virtual_batch_size is not None:\n",
    "            virtual_batch_size = int(virtual_batch_size)\n",
    "\n",
    "        if norm_type not in ['batch', 'group']:\n",
    "            raise ValueError(\"`norm_type` must be either `batch` or `group`\")\n",
    "\n",
    "        self.feature_columns = feature_columns\n",
    "        self.num_features = num_features\n",
    "        self.feature_dim = feature_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.num_decision_steps = num_decision_steps\n",
    "        self.relaxation_factor = relaxation_factor\n",
    "        self.sparsity_coefficient = sparsity_coefficient\n",
    "        self.norm_type = norm_type\n",
    "        self.batch_momentum = batch_momentum\n",
    "        self.virtual_batch_size = virtual_batch_size\n",
    "        self.num_groups = num_groups\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        if num_decision_steps > 1:\n",
    "            features_for_coeff = feature_dim - output_dim\n",
    "            print(f\"[TabNet]: {features_for_coeff} features will be used for decision steps.\")\n",
    "\n",
    "        if self.feature_columns is not None:\n",
    "            self.input_features = tf.keras.layers.DenseFeatures(feature_columns, trainable=True)\n",
    "\n",
    "            if self.norm_type == 'batch':\n",
    "                self.input_bn = tf.keras.layers.BatchNormalization(axis=-1, momentum=batch_momentum, name='input_bn')\n",
    "            else:\n",
    "                self.input_bn = GroupNormalization(axis=-1, groups=self.num_groups, name='input_gn')\n",
    "\n",
    "        else:\n",
    "            self.input_features = None\n",
    "            self.input_bn = None\n",
    "\n",
    "        self.transform_f1 = TransformBlock(2 * self.feature_dim, self.norm_type,\n",
    "                                           self.batch_momentum, self.virtual_batch_size, self.num_groups,\n",
    "                                           block_name='f1')\n",
    "\n",
    "        self.transform_f2 = TransformBlock(2 * self.feature_dim, self.norm_type,\n",
    "                                           self.batch_momentum, self.virtual_batch_size, self.num_groups,\n",
    "                                           block_name='f2')\n",
    "\n",
    "        self.transform_f3_list = [\n",
    "            TransformBlock(2 * self.feature_dim, self.norm_type,\n",
    "                           self.batch_momentum, self.virtual_batch_size, self.num_groups, block_name=f'f3_{i}')\n",
    "            for i in range(self.num_decision_steps)\n",
    "        ]\n",
    "\n",
    "        self.transform_f4_list = [\n",
    "            TransformBlock(2 * self.feature_dim, self.norm_type,\n",
    "                           self.batch_momentum, self.virtual_batch_size, self.num_groups, block_name=f'f4_{i}')\n",
    "            for i in range(self.num_decision_steps)\n",
    "        ]\n",
    "\n",
    "        self.transform_coef_list = [\n",
    "            TransformBlock(self.num_features, self.norm_type,\n",
    "                           self.batch_momentum, self.virtual_batch_size, self.num_groups, block_name=f'coef_{i}')\n",
    "            for i in range(self.num_decision_steps - 1)\n",
    "        ]\n",
    "\n",
    "        self._step_feature_selection_masks = None\n",
    "        self._step_aggregate_feature_selection_mask = None\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if self.input_features is not None:\n",
    "            features = self.input_features(inputs)\n",
    "            features = self.input_bn(features, training=training)\n",
    "\n",
    "        else:\n",
    "            features = inputs\n",
    "\n",
    "        batch_size = tf.shape(features)[0]\n",
    "        self._step_feature_selection_masks = []\n",
    "        self._step_aggregate_feature_selection_mask = None\n",
    "\n",
    "        # Initializes decision-step dependent variables.\n",
    "        output_aggregated = tf.zeros([batch_size, self.output_dim])\n",
    "        masked_features = features\n",
    "        mask_values = tf.zeros([batch_size, self.num_features])\n",
    "        aggregated_mask_values = tf.zeros([batch_size, self.num_features])\n",
    "        complementary_aggregated_mask_values = tf.ones(\n",
    "            [batch_size, self.num_features])\n",
    "\n",
    "        total_entropy = 0.0\n",
    "        entropy_loss = 0.\n",
    "\n",
    "        for ni in range(self.num_decision_steps):\n",
    "            # Feature transformer with two shared and two decision step dependent\n",
    "            # blocks is used below.=\n",
    "            transform_f1 = self.transform_f1(masked_features, training=training)\n",
    "            transform_f1 = glu(transform_f1, self.feature_dim)\n",
    "\n",
    "            transform_f2 = self.transform_f2(transform_f1, training=training)\n",
    "            transform_f2 = (glu(transform_f2, self.feature_dim) +\n",
    "                            transform_f1) * tf.math.sqrt(0.5)\n",
    "\n",
    "            transform_f3 = self.transform_f3_list[ni](transform_f2, training=training)\n",
    "            transform_f3 = (glu(transform_f3, self.feature_dim) +\n",
    "                            transform_f2) * tf.math.sqrt(0.5)\n",
    "\n",
    "            transform_f4 = self.transform_f4_list[ni](transform_f3, training=training)\n",
    "            transform_f4 = (glu(transform_f4, self.feature_dim) +\n",
    "                            transform_f3) * tf.math.sqrt(0.5)\n",
    "\n",
    "            if (ni > 0 or self.num_decision_steps == 1):\n",
    "                decision_out = tf.nn.relu(transform_f4[:, :self.output_dim])\n",
    "\n",
    "                # Decision aggregation.\n",
    "                output_aggregated += decision_out\n",
    "\n",
    "                # Aggregated masks are used for visualization of the\n",
    "                # feature importance attributes.\n",
    "                scale_agg = tf.reduce_sum(decision_out, axis=1, keepdims=True)\n",
    "\n",
    "                if self.num_decision_steps > 1:\n",
    "                    scale_agg = scale_agg / tf.cast(self.num_decision_steps - 1, tf.float32)\n",
    "\n",
    "                aggregated_mask_values += mask_values * scale_agg\n",
    "\n",
    "            features_for_coef = transform_f4[:, self.output_dim:]\n",
    "\n",
    "            if ni < (self.num_decision_steps - 1):\n",
    "                # Determines the feature masks via linear and nonlinear\n",
    "                # transformations, taking into account of aggregated feature use.\n",
    "                mask_values = self.transform_coef_list[ni](features_for_coef, training=training)\n",
    "                mask_values *= complementary_aggregated_mask_values\n",
    "                mask_values = sparsemax(mask_values, axis=-1)\n",
    "\n",
    "                # Relaxation factor controls the amount of reuse of features between\n",
    "                # different decision blocks and updated with the values of\n",
    "                # coefficients.\n",
    "                complementary_aggregated_mask_values *= (\n",
    "                        self.relaxation_factor - mask_values)\n",
    "\n",
    "                # Entropy is used to penalize the amount of sparsity in feature\n",
    "                # selection.\n",
    "                total_entropy += tf.reduce_mean(\n",
    "                    tf.reduce_sum(\n",
    "                        -mask_values * tf.math.log(mask_values + self.epsilon), axis=1)) / (\n",
    "                                     tf.cast(self.num_decision_steps - 1, tf.float32))\n",
    "\n",
    "                # Add entropy loss\n",
    "                entropy_loss = total_entropy\n",
    "\n",
    "                # Feature selection.\n",
    "                masked_features = tf.multiply(mask_values, features)\n",
    "\n",
    "                # Visualization of the feature selection mask at decision step ni\n",
    "                # tf.summary.image(\n",
    "                #     \"Mask for step\" + str(ni),\n",
    "                #     tf.expand_dims(tf.expand_dims(mask_values, 0), 3),\n",
    "                #     max_outputs=1)\n",
    "                mask_at_step_i = tf.expand_dims(tf.expand_dims(mask_values, 0), 3)\n",
    "                self._step_feature_selection_masks.append(mask_at_step_i)\n",
    "\n",
    "            else:\n",
    "                # This branch is needed for correct compilation by tf.autograph\n",
    "                entropy_loss = 0.\n",
    "\n",
    "        # Adds the loss automatically\n",
    "        self.add_loss(self.sparsity_coefficient * entropy_loss)\n",
    "\n",
    "        # Visualization of the aggregated feature importances\n",
    "        # tf.summary.image(\n",
    "        #     \"Aggregated mask\",\n",
    "        #     tf.expand_dims(tf.expand_dims(aggregated_mask_values, 0), 3),\n",
    "        #     max_outputs=1)\n",
    "\n",
    "        agg_mask = tf.expand_dims(tf.expand_dims(aggregated_mask_values, 0), 3)\n",
    "        self._step_aggregate_feature_selection_mask = agg_mask\n",
    "\n",
    "        return output_aggregated\n",
    "\n",
    "    @property\n",
    "    def feature_selection_masks(self):\n",
    "        return self._step_feature_selection_masks\n",
    "\n",
    "    @property\n",
    "    def aggregate_feature_selection_mask(self):\n",
    "        return self._step_aggregate_feature_selection_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:45.839034Z",
     "iopub.status.busy": "2020-11-10T19:40:45.837125Z",
     "iopub.status.idle": "2020-11-10T19:40:45.839760Z",
     "shell.execute_reply": "2020-11-10T19:40:45.840244Z"
    },
    "papermill": {
     "duration": 0.218847,
     "end_time": "2020-11-10T19:40:45.840379",
     "exception": false,
     "start_time": "2020-11-10T19:40:45.621532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackedTabNet(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, feature_columns,\n",
    "                 num_layers=1,\n",
    "                 feature_dim=64,\n",
    "                 output_dim=64,\n",
    "                 num_features=None,\n",
    "                 num_decision_steps=5,\n",
    "                 relaxation_factor=1.5,\n",
    "                 sparsity_coefficient=1e-5,\n",
    "                 norm_type='group',\n",
    "                 batch_momentum=0.98,\n",
    "                 virtual_batch_size=None,\n",
    "                 num_groups=2,\n",
    "                 epsilon=1e-5,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(StackedTabNet, self).__init__(**kwargs)\n",
    "\n",
    "        if num_layers < 1:\n",
    "            raise ValueError(\"`num_layers` cannot be less than 1\")\n",
    "\n",
    "        if type(feature_dim) not in [list, tuple]:\n",
    "            feature_dim = [feature_dim] * num_layers\n",
    "\n",
    "        if type(output_dim) not in [list, tuple]:\n",
    "            output_dim = [output_dim] * num_layers\n",
    "\n",
    "        if len(feature_dim) != num_layers:\n",
    "            raise ValueError(\"`feature_dim` must be a list of length `num_layers`\")\n",
    "\n",
    "        if len(output_dim) != num_layers:\n",
    "            raise ValueError(\"`output_dim` must be a list of length `num_layers`\")\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        layers = []\n",
    "        layers.append(TabNet(feature_columns=feature_columns,\n",
    "                             num_features=num_features,\n",
    "                             feature_dim=feature_dim[0],\n",
    "                             output_dim=output_dim[0],\n",
    "                             num_decision_steps=num_decision_steps,\n",
    "                             relaxation_factor=relaxation_factor,\n",
    "                             sparsity_coefficient=sparsity_coefficient,\n",
    "                             norm_type=norm_type,\n",
    "                             batch_momentum=batch_momentum,\n",
    "                             virtual_batch_size=virtual_batch_size,\n",
    "                             num_groups=num_groups,\n",
    "                             epsilon=epsilon))\n",
    "\n",
    "        for layer_idx in range(1, num_layers):\n",
    "            layers.append(TabNet(feature_columns=None,\n",
    "                                 num_features=output_dim[layer_idx - 1],\n",
    "                                 feature_dim=feature_dim[layer_idx],\n",
    "                                 output_dim=output_dim[layer_idx],\n",
    "                                 num_decision_steps=num_decision_steps,\n",
    "                                 relaxation_factor=relaxation_factor,\n",
    "                                 sparsity_coefficient=sparsity_coefficient,\n",
    "                                 norm_type=norm_type,\n",
    "                                 batch_momentum=batch_momentum,\n",
    "                                 virtual_batch_size=virtual_batch_size,\n",
    "                                 num_groups=num_groups,\n",
    "                                 epsilon=epsilon))\n",
    "\n",
    "        self.tabnet_layers = layers\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.tabnet_layers[0](inputs, training=training)\n",
    "\n",
    "        for layer_idx in range(1, self.num_layers):\n",
    "            x = self.tabnet_layers[layer_idx](x, training=training)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def tabnets(self):\n",
    "        return self.tabnet_layers\n",
    "\n",
    "    @property\n",
    "    def feature_selection_masks(self):\n",
    "        return [tabnet.feature_selection_masks\n",
    "                for tabnet in self.tabnet_layers]\n",
    "\n",
    "    @property\n",
    "    def aggregate_feature_selection_mask(self):\n",
    "        return [tabnet.aggregate_feature_selection_mask\n",
    "                for tabnet in self.tabnet_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:46.227818Z",
     "iopub.status.busy": "2020-11-10T19:40:46.226835Z",
     "iopub.status.idle": "2020-11-10T19:40:46.271403Z",
     "shell.execute_reply": "2020-11-10T19:40:46.272252Z"
    },
    "papermill": {
     "duration": 0.250852,
     "end_time": "2020-11-10T19:40:46.272512",
     "exception": false,
     "start_time": "2020-11-10T19:40:46.021660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StackedTabNetClassifier(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, feature_columns,\n",
    "                 num_classes,\n",
    "                 num_layers=1,\n",
    "                 feature_dim=64,\n",
    "                 output_dim=64,\n",
    "                 num_features=None,\n",
    "                 num_decision_steps=5,\n",
    "                 relaxation_factor=1.5,\n",
    "                 sparsity_coefficient=1e-5,\n",
    "                 norm_type='group',\n",
    "                 batch_momentum=0.98,\n",
    "                 virtual_batch_size=None,\n",
    "                 num_groups=2,\n",
    "                 epsilon=1e-5,\n",
    "                 **kwargs):\n",
    "\n",
    "        super(StackedTabNetClassifier, self).__init__(**kwargs)\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.stacked_tabnet0 = StackedTabNet(feature_columns=feature_columns,\n",
    "                                             feature_dim=feature_dim,\n",
    "                                             output_dim=output_dim,\n",
    "                                             num_features=num_features,\n",
    "                                             num_layers = num_layers,\n",
    "                                             num_decision_steps=num_decision_steps,\n",
    "                                             relaxation_factor=relaxation_factor,\n",
    "                                             sparsity_coefficient=sparsity_coefficient,\n",
    "                                             norm_type=norm_type,\n",
    "                                             batch_momentum=batch_momentum,\n",
    "                                             virtual_batch_size=virtual_batch_size,\n",
    "                                             num_groups=num_groups,\n",
    "                                             epsilon=epsilon)\n",
    "        \n",
    "        self.stacked_tabnet1 = StackedTabNet(feature_columns=feature_columns,\n",
    "                                             feature_dim=128,\n",
    "                                             output_dim=64,\n",
    "                                             num_features=num_features,\n",
    "                                             num_layers = num_layers,\n",
    "                                             num_decision_steps=num_decision_steps,\n",
    "                                             relaxation_factor=relaxation_factor,\n",
    "                                             sparsity_coefficient=sparsity_coefficient,\n",
    "                                             norm_type=norm_type,\n",
    "                                             batch_momentum=batch_momentum,\n",
    "                                             virtual_batch_size=virtual_batch_size,\n",
    "                                             num_groups=num_groups,\n",
    "                                             epsilon=epsilon)\n",
    "        \n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.batch_norm0 = BatchNormalization()\n",
    "        self.dropout3 = Dropout(0.2)\n",
    "        self.batch_norm = BatchNormalization()\n",
    "        self.dense1 = tfa.layers.WeightNormalization(Dense(6144,activation='relu'))\n",
    "        self.batch_norm1 = BatchNormalization(axis=-1, momentum=batch_momentum)\n",
    "        self.dropout1 = Dropout(0.4)\n",
    "        \n",
    "        self.dense11 = tfa.layers.WeightNormalization(Dense(6144,activation='relu'))\n",
    "        self.batch_norm11 = BatchNormalization(axis=-1, momentum=batch_momentum)\n",
    "        self.dropout11 = Dropout(0.4)\n",
    "        \n",
    "        self.dropout4 = Dropout(0.2)\n",
    "        self.batch_norm4 = BatchNormalization()\n",
    "        self.dense4 = tfa.layers.WeightNormalization(Dense(2048,activation='relu'))\n",
    "        self.batch_norm5 = BatchNormalization(axis=-1, momentum=batch_momentum)\n",
    "        self.dropout5 = Dropout(0.4)\n",
    "        self.dense5 = tfa.layers.WeightNormalization(Dense(2048,activation='relu'))\n",
    "        self.batch_norm6 = BatchNormalization(axis=-1, momentum=batch_momentum)\n",
    "        self.dropout6 = Dropout(0.4)\n",
    "        \n",
    "        self.clf0 = tfa.layers.WeightNormalization(Dense(num_classes, activation='sigmoid', use_bias=False), name='classifier0')\n",
    "        \n",
    "        self.clf = tfa.layers.WeightNormalization(Dense(num_classes, activation='softmax', use_bias=False), name='classifier1')\n",
    "        \n",
    "        self.clf1 = tfa.layers.WeightNormalization(Dense(num_classes, activation='sigmoid', use_bias=False), name='classifier2')\n",
    "    def call(self, inputs, training=None):\n",
    "        #inputs0, inputs1, inputs2 = inputs\n",
    "        #self.act3 = self.dropout5(self.batch_norm5(self.dense4(self.batch_norm4(self.dropout4(inputs)))))\n",
    "        #self.act4 = self.dropout6(self.batch_norm6(self.dense5(self.act3)))\n",
    "        #out2 = self.clf1(self.act4)\n",
    "        #o = self.clf(self.act4)\n",
    "        #self.concat0 = tf.keras.layers.Concatenate(axis=-1)([o,inputs])\n",
    "        self.activations0 = self.stacked_tabnet0(self.dropout(self.batch_norm0(inputs)), training=training)\n",
    "        out0 = self.clf0(self.activations0)\n",
    "\n",
    "        #self.concat = tf.keras.layers.Concatenate(axis=-1)([self.activations0,self.act4,inputs])\n",
    "        #self.act1 = self.dropout1(self.batch_norm1(self.dense1(self.batch_norm(self.dropout3(self.activations0)))))\n",
    "        #self.act2 = self.dropout11(self.batch_norm11(self.dense11(self.act1)))\n",
    "        #out1 = self.clf(self.act2)\n",
    "        \n",
    "        #out = tf.keras.layers.Average()([out0,out2])\n",
    "\n",
    "        return out0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:46.873662Z",
     "iopub.status.busy": "2020-11-10T19:40:46.872788Z",
     "iopub.status.idle": "2020-11-10T19:40:46.884894Z",
     "shell.execute_reply": "2020-11-10T19:40:46.886078Z"
    },
    "papermill": {
     "duration": 0.310727,
     "end_time": "2020-11-10T19:40:46.886287",
     "exception": false,
     "start_time": "2020-11-10T19:40:46.575560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "initializer = tf.keras.initializers.GlorotNormal()\n",
    "col_names = feature_cols.copy()\n",
    "feature_columns = []\n",
    "for col_name in col_names:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(str(col_name)))\n",
    "num_classes = len(target_cols)\n",
    "num_features=len(feature_cols)\n",
    "\n",
    "def creat_model():\n",
    "    #tab = TabNet(feature_columns=feature_columns, num_classes=num_classes, num_features=num_features,feature_dim=64, output_dim=32)\n",
    "    #model = tfa.layers.WeightNormalization(Dense(num_targets,activation='sigmoid'))(tab)\n",
    "    model = StackedTabNetClassifier(feature_columns = None, num_classes = 206, num_layers = 2, \n",
    "                                    feature_dim = 1024, output_dim = 512, num_features = len(feature_cols),\n",
    "                                    num_decision_steps = 1, relaxation_factor = 1.5,\n",
    "                                    sparsity_coefficient = 1e-5, batch_momentum = 0.98,\n",
    "                                    virtual_batch_size = None, norm_type = 'group',\n",
    "                                    num_groups = 1)\n",
    "    return model\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.264421,
     "end_time": "2020-11-10T19:40:47.438229",
     "exception": false,
     "start_time": "2020-11-10T19:40:47.173808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **1. Smoothing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.182408,
     "end_time": "2020-11-10T19:40:47.843701",
     "exception": false,
     "start_time": "2020-11-10T19:40:47.661293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Single fold training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:48.240853Z",
     "iopub.status.busy": "2020-11-10T19:40:48.239961Z",
     "iopub.status.idle": "2020-11-10T19:40:48.244066Z",
     "shell.execute_reply": "2020-11-10T19:40:48.243224Z"
    },
    "papermill": {
     "duration": 0.212347,
     "end_time": "2020-11-10T19:40:48.244169",
     "exception": false,
     "start_time": "2020-11-10T19:40:48.031822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(fold, seed):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
    "\n",
    "    #train_ds,valid_ds = data_load(x_train, y_train,x_valid, y_valid)\n",
    "        \n",
    "    model = creat_model()\n",
    "    step = tf.Variable(0, trainable=False)\n",
    "    #schedule = tf.optimizers.schedules.PiecewiseConstantDecay([100, 200], [2e-2, 1e-2, 1e-2])\n",
    "    # lr and wd can be a function or a tensor\n",
    "    #lr = tf.keras.optimizers.schedules.ExponentialDecay(1e-3, decay_steps=500, decay_rate=0.9, staircase=False)\n",
    "    lr = 1e-3 #0.007809719000164987 \n",
    "    wd = 1e-5\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=wd)\n",
    "\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 3, verbose = 1, min_delta = 1e-4, mode = 'min')\n",
    "\n",
    "    ckp = ModelCheckpoint(f'TabNet_{seed}_{fold}.hdf5', monitor = 'val_loss', verbose = 0, save_best_only = True, save_weights_only = True, mode = 'min')\n",
    "    losses = { 'classifier2':\"binary_crossentropy\",'classifier2':'binary_crossentropy'}\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.001)\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
    "    best_loss = np.inf\n",
    "    model.compile(optimizer=tfa.optimizers.Lookahead(optimizer,sync_period=10), loss=loss)\n",
    "    model.fit(x_train,y_train, validation_data=(x_valid, y_valid),epochs= 30,callbacks=[reduce_lr_loss,ckp],batch_size = 128, verbose=2)\n",
    "    model.load_weights(f'TabNet_{seed}_{fold}.hdf5')\n",
    "    #valid_preds0 , valid_preds1 = model.predict(valid_ds)\n",
    "    #oof[val_idx] = 0.5*(valid_preds0 + valid_preds1)\n",
    "    valid_preds = model.predict(x_valid,batch_size = 128)\n",
    "    oof[val_idx] = valid_preds\n",
    "\n",
    "    print('final_val_loss = ', log_loss(y_valid, valid_preds)/206)\n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    #not_ds,test_ds = data_load2(x_train, y_train,x_test, [])\n",
    "    \n",
    "    predictions = np.zeros((len(test_), target.iloc[:, 1:].shape[1]))\n",
    "    #predictions0 ,  predictions1= model.predict(test_ds)\n",
    "    #predictions = 0.5*(predictions0 + predictions1)\n",
    "    predictions = model.predict(x_test,batch_size = 128)\n",
    "        \n",
    "    \n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:48.637803Z",
     "iopub.status.busy": "2020-11-10T19:40:48.637031Z",
     "iopub.status.idle": "2020-11-10T19:40:48.639816Z",
     "shell.execute_reply": "2020-11-10T19:40:48.639351Z"
    },
    "papermill": {
     "duration": 0.202421,
     "end_time": "2020-11-10T19:40:48.639916",
     "exception": false,
     "start_time": "2020-11-10T19:40:48.437495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        print('*'*25,' ',fold,' ','*'*25)\n",
    "        oof_, pred_ = run_training(fold, seed)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T19:40:49.016548Z",
     "iopub.status.busy": "2020-11-10T19:40:49.014884Z",
     "iopub.status.idle": "2020-11-10T20:09:33.845817Z",
     "shell.execute_reply": "2020-11-10T20:09:33.844678Z"
    },
    "papermill": {
     "duration": 1725.023845,
     "end_time": "2020-11-10T20:09:33.845966",
     "exception": false,
     "start_time": "2020-11-10T19:40:48.822121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n",
      "*************************   0   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0437 - val_loss: 0.0252\n",
      "Epoch 2/30\n",
      "138/138 - 3s - loss: 0.0255 - val_loss: 0.0233\n",
      "Epoch 3/30\n",
      "138/138 - 4s - loss: 0.0238 - val_loss: 0.0226\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0228 - val_loss: 0.0217\n",
      "Epoch 5/30\n",
      "138/138 - 4s - loss: 0.0221 - val_loss: 0.0215\n",
      "Epoch 6/30\n",
      "138/138 - 4s - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0212 - val_loss: 0.0215\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0206 - val_loss: 0.0208\n",
      "Epoch 10/30\n",
      "138/138 - 4s - loss: 0.0204 - val_loss: 0.0206\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0201 - val_loss: 0.0204\n",
      "Epoch 12/30\n",
      "138/138 - 3s - loss: 0.0199 - val_loss: 0.0205\n",
      "Epoch 13/30\n",
      "138/138 - 3s - loss: 0.0197 - val_loss: 0.0206\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0195 - val_loss: 0.0204\n",
      "Epoch 15/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 16/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 17/30\n",
      "138/138 - 3s - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 4s - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 20/30\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 21/30\n",
      "138/138 - 3s - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 23/30\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 24/30\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 26/30\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 27/30\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 29/30\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 30/30\n",
      "138/138 - 4s - loss: 0.0186 - val_loss: 0.0202\n",
      "final_val_loss =  0.0127286565204967\n",
      "*************************   1   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0431 - val_loss: 0.0249\n",
      "Epoch 2/30\n",
      "138/138 - 4s - loss: 0.0254 - val_loss: 0.0234\n",
      "Epoch 3/30\n",
      "138/138 - 3s - loss: 0.0239 - val_loss: 0.0224\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0228 - val_loss: 0.0221\n",
      "Epoch 5/30\n",
      "138/138 - 3s - loss: 0.0221 - val_loss: 0.0214\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0210\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 8/30\n",
      "138/138 - 4s - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 10/30\n",
      "138/138 - 4s - loss: 0.0203 - val_loss: 0.0206\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0201 - val_loss: 0.0206\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 4s - loss: 0.0199 - val_loss: 0.0205\n",
      "Epoch 13/30\n",
      "138/138 - 4s - loss: 0.0195 - val_loss: 0.0203\n",
      "Epoch 14/30\n",
      "138/138 - 3s - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 15/30\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 17/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0204\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 20/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 21/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0204\n",
      "Epoch 23/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 24/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 26/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 27/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 29/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 30/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0204\n",
      "final_val_loss =  0.012962144437318258\n",
      "*************************   2   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0440 - val_loss: 0.0246\n",
      "Epoch 2/30\n",
      "138/138 - 3s - loss: 0.0253 - val_loss: 0.0234\n",
      "Epoch 3/30\n",
      "138/138 - 3s - loss: 0.0239 - val_loss: 0.0227\n",
      "Epoch 4/30\n",
      "138/138 - 4s - loss: 0.0228 - val_loss: 0.0222\n",
      "Epoch 5/30\n",
      "138/138 - 4s - loss: 0.0220 - val_loss: 0.0216\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 7/30\n",
      "138/138 - 4s - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0206 - val_loss: 0.0210\n",
      "Epoch 10/30\n",
      "138/138 - 4s - loss: 0.0203 - val_loss: 0.0207\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0201 - val_loss: 0.0211\n",
      "Epoch 12/30\n",
      "138/138 - 3s - loss: 0.0199 - val_loss: 0.0207\n",
      "Epoch 13/30\n",
      "138/138 - 3s - loss: 0.0197 - val_loss: 0.0202\n",
      "Epoch 14/30\n",
      "138/138 - 4s - loss: 0.0195 - val_loss: 0.0203\n",
      "Epoch 15/30\n",
      "138/138 - 4s - loss: 0.0193 - val_loss: 0.0203\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0210\n",
      "Epoch 17/30\n",
      "138/138 - 3s - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 20/30\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 21/30\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 23/30\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 24/30\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 26/30\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0203\n",
      "Epoch 27/30\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0203\n",
      "Epoch 29/30\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 30/30\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0203\n",
      "final_val_loss =  0.012893371734149674\n",
      "*************************   3   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0427 - val_loss: 0.0252\n",
      "Epoch 2/30\n",
      "138/138 - 4s - loss: 0.0253 - val_loss: 0.0231\n",
      "Epoch 3/30\n",
      "138/138 - 3s - loss: 0.0238 - val_loss: 0.0231\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0228 - val_loss: 0.0228\n",
      "Epoch 5/30\n",
      "138/138 - 3s - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0222\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0211 - val_loss: 0.0219\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0209 - val_loss: 0.0216\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0206 - val_loss: 0.0212\n",
      "Epoch 10/30\n",
      "138/138 - 3s - loss: 0.0203 - val_loss: 0.0210\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0201 - val_loss: 0.0210\n",
      "Epoch 12/30\n",
      "138/138 - 3s - loss: 0.0199 - val_loss: 0.0207\n",
      "Epoch 13/30\n",
      "138/138 - 3s - loss: 0.0197 - val_loss: 0.0208\n",
      "Epoch 14/30\n",
      "138/138 - 3s - loss: 0.0194 - val_loss: 0.0206\n",
      "Epoch 15/30\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 16/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0207\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 4s - loss: 0.0189 - val_loss: 0.0205\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0205\n",
      "Epoch 19/30\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 21/30\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 22/30\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 24/30\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 25/30\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 27/30\n",
      "138/138 - 3s - loss: 0.0180 - val_loss: 0.0205\n",
      "Epoch 28/30\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 30/30\n",
      "138/138 - 4s - loss: 0.0181 - val_loss: 0.0205\n",
      "final_val_loss =  0.012871312877372924\n",
      "*************************   4   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0429 - val_loss: 0.0259\n",
      "Epoch 2/30\n",
      "138/138 - 4s - loss: 0.0253 - val_loss: 0.0236\n",
      "Epoch 3/30\n",
      "138/138 - 4s - loss: 0.0238 - val_loss: 0.0226\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0228 - val_loss: 0.0222\n",
      "Epoch 5/30\n",
      "138/138 - 3s - loss: 0.0221 - val_loss: 0.0217\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0217\n",
      "Epoch 7/30\n",
      "138/138 - 4s - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0210 - val_loss: 0.0213\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0207 - val_loss: 0.0210\n",
      "Epoch 10/30\n",
      "138/138 - 3s - loss: 0.0204 - val_loss: 0.0206\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0202 - val_loss: 0.0209\n",
      "Epoch 12/30\n",
      "138/138 - 3s - loss: 0.0199 - val_loss: 0.0206\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0198 - val_loss: 0.0207\n",
      "Epoch 14/30\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 15/30\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 16/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0205\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 4s - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 19/30\n",
      "138/138 - 4s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0205\n",
      "Epoch 21/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 22/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 24/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 25/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 27/30\n",
      "138/138 - 4s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 28/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 30/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0204\n",
      "final_val_loss =  0.012834004470191026\n",
      "_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n",
      "*************************   0   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0435 - val_loss: 0.0249\n",
      "Epoch 2/30\n",
      "138/138 - 4s - loss: 0.0254 - val_loss: 0.0234\n",
      "Epoch 3/30\n",
      "138/138 - 3s - loss: 0.0238 - val_loss: 0.0224\n",
      "Epoch 4/30\n",
      "138/138 - 4s - loss: 0.0228 - val_loss: 0.0221\n",
      "Epoch 5/30\n",
      "138/138 - 3s - loss: 0.0221 - val_loss: 0.0215\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0212\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0212 - val_loss: 0.0209\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 10/30\n",
      "138/138 - 3s - loss: 0.0204 - val_loss: 0.0204\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0202 - val_loss: 0.0204\n",
      "Epoch 12/30\n",
      "138/138 - 3s - loss: 0.0199 - val_loss: 0.0206\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0197 - val_loss: 0.0208\n",
      "Epoch 14/30\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0202\n",
      "Epoch 15/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0202\n",
      "Epoch 16/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 19/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 4s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 21/30\n",
      "138/138 - 4s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 22/30\n",
      "138/138 - 4s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 24/30\n",
      "138/138 - 4s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 25/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0201\n",
      "Epoch 27/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0201\n",
      "Epoch 28/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0201\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0201\n",
      "Epoch 30/30\n",
      "138/138 - 4s - loss: 0.0189 - val_loss: 0.0201\n",
      "final_val_loss =  0.01267209739474359\n",
      "*************************   1   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0440 - val_loss: 0.0249\n",
      "Epoch 2/30\n",
      "138/138 - 3s - loss: 0.0254 - val_loss: 0.0231\n",
      "Epoch 3/30\n",
      "138/138 - 4s - loss: 0.0238 - val_loss: 0.0222\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0228 - val_loss: 0.0218\n",
      "Epoch 5/30\n",
      "138/138 - 4s - loss: 0.0221 - val_loss: 0.0214\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0212\n",
      "Epoch 7/30\n",
      "138/138 - 4s - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 9/30\n",
      "138/138 - 4s - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 10/30\n",
      "138/138 - 3s - loss: 0.0203 - val_loss: 0.0206\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0202 - val_loss: 0.0208\n",
      "Epoch 12/30\n",
      "138/138 - 3s - loss: 0.0197 - val_loss: 0.0205\n",
      "Epoch 13/30\n",
      "138/138 - 3s - loss: 0.0195 - val_loss: 0.0205\n",
      "Epoch 14/30\n",
      "138/138 - 3s - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 16/30\n",
      "138/138 - 3s - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 17/30\n",
      "138/138 - 4s - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 19/30\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 20/30\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 22/30\n",
      "138/138 - 4s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 23/30\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 25/30\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 26/30\n",
      "138/138 - 4s - loss: 0.0194 - val_loss: 0.0204\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "138/138 - 4s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 28/30\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 29/30\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "138/138 - 3s - loss: 0.0194 - val_loss: 0.0204\n",
      "final_val_loss =  0.012965872013071157\n",
      "*************************   2   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0435 - val_loss: 0.0254\n",
      "Epoch 2/30\n",
      "138/138 - 4s - loss: 0.0255 - val_loss: 0.0236\n",
      "Epoch 3/30\n",
      "138/138 - 3s - loss: 0.0239 - val_loss: 0.0231\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0228 - val_loss: 0.0218\n",
      "Epoch 5/30\n",
      "138/138 - 3s - loss: 0.0221 - val_loss: 0.0218\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0218\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0212 - val_loss: 0.0213\n",
      "Epoch 8/30\n",
      "138/138 - 4s - loss: 0.0209 - val_loss: 0.0213\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0206 - val_loss: 0.0209\n",
      "Epoch 10/30\n",
      "138/138 - 3s - loss: 0.0204 - val_loss: 0.0209\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0201 - val_loss: 0.0206\n",
      "Epoch 12/30\n",
      "138/138 - 4s - loss: 0.0199 - val_loss: 0.0207\n",
      "Epoch 13/30\n",
      "138/138 - 3s - loss: 0.0197 - val_loss: 0.0205\n",
      "Epoch 14/30\n",
      "138/138 - 3s - loss: 0.0195 - val_loss: 0.0205\n",
      "Epoch 15/30\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 16/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0205\n",
      "Epoch 17/30\n",
      "138/138 - 3s - loss: 0.0188 - val_loss: 0.0206\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 19/30\n",
      "138/138 - 3s - loss: 0.0185 - val_loss: 0.0204\n",
      "Epoch 20/30\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0204\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0204\n",
      "Epoch 22/30\n",
      "138/138 - 3s - loss: 0.0176 - val_loss: 0.0204\n",
      "Epoch 23/30\n",
      "138/138 - 3s - loss: 0.0175 - val_loss: 0.0204\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0174 - val_loss: 0.0205\n",
      "Epoch 25/30\n",
      "138/138 - 3s - loss: 0.0173 - val_loss: 0.0205\n",
      "Epoch 26/30\n",
      "138/138 - 3s - loss: 0.0173 - val_loss: 0.0205\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0173 - val_loss: 0.0205\n",
      "Epoch 28/30\n",
      "138/138 - 3s - loss: 0.0173 - val_loss: 0.0205\n",
      "Epoch 29/30\n",
      "138/138 - 3s - loss: 0.0172 - val_loss: 0.0205\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0172 - val_loss: 0.0205\n",
      "final_val_loss =  0.012692951634339235\n",
      "*************************   3   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0431 - val_loss: 0.0252\n",
      "Epoch 2/30\n",
      "138/138 - 3s - loss: 0.0254 - val_loss: 0.0235\n",
      "Epoch 3/30\n",
      "138/138 - 3s - loss: 0.0238 - val_loss: 0.0230\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0228 - val_loss: 0.0224\n",
      "Epoch 5/30\n",
      "138/138 - 3s - loss: 0.0221 - val_loss: 0.0217\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0221\n",
      "Epoch 7/30\n",
      "138/138 - 4s - loss: 0.0212 - val_loss: 0.0215\n",
      "Epoch 8/30\n",
      "138/138 - 4s - loss: 0.0209 - val_loss: 0.0214\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0206 - val_loss: 0.0214\n",
      "Epoch 10/30\n",
      "138/138 - 3s - loss: 0.0203 - val_loss: 0.0208\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0201 - val_loss: 0.0210\n",
      "Epoch 12/30\n",
      "138/138 - 3s - loss: 0.0198 - val_loss: 0.0209\n",
      "Epoch 13/30\n",
      "138/138 - 3s - loss: 0.0196 - val_loss: 0.0207\n",
      "Epoch 14/30\n",
      "138/138 - 3s - loss: 0.0194 - val_loss: 0.0207\n",
      "Epoch 15/30\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 16/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0205\n",
      "Epoch 17/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0206\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0206\n",
      "Epoch 19/30\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 20/30\n",
      "138/138 - 3s - loss: 0.0179 - val_loss: 0.0205\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0179 - val_loss: 0.0205\n",
      "Epoch 22/30\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 23/30\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 25/30\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 26/30\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0179 - val_loss: 0.0205\n",
      "Epoch 28/30\n",
      "138/138 - 4s - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 29/30\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0205\n",
      "final_val_loss =  0.01293170724306865\n",
      "*************************   4   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 4s - loss: 0.0432 - val_loss: 0.0249\n",
      "Epoch 2/30\n",
      "138/138 - 3s - loss: 0.0254 - val_loss: 0.0235\n",
      "Epoch 3/30\n",
      "138/138 - 4s - loss: 0.0238 - val_loss: 0.0227\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0227 - val_loss: 0.0234\n",
      "Epoch 5/30\n",
      "138/138 - 3s - loss: 0.0221 - val_loss: 0.0219\n",
      "Epoch 6/30\n",
      "138/138 - 4s - loss: 0.0216 - val_loss: 0.0216\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0212 - val_loss: 0.0217\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0209 - val_loss: 0.0212\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0206 - val_loss: 0.0213\n",
      "Epoch 10/30\n",
      "138/138 - 4s - loss: 0.0204 - val_loss: 0.0208\n",
      "Epoch 11/30\n",
      "138/138 - 4s - loss: 0.0201 - val_loss: 0.0208\n",
      "Epoch 12/30\n",
      "138/138 - 4s - loss: 0.0199 - val_loss: 0.0205\n",
      "Epoch 13/30\n",
      "138/138 - 3s - loss: 0.0197 - val_loss: 0.0205\n",
      "Epoch 14/30\n",
      "138/138 - 4s - loss: 0.0195 - val_loss: 0.0204\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 16/30\n",
      "138/138 - 4s - loss: 0.0188 - val_loss: 0.0203\n",
      "Epoch 17/30\n",
      "138/138 - 3s - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0185 - val_loss: 0.0204\n",
      "Epoch 20/30\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0204\n",
      "Epoch 21/30\n",
      "138/138 - 3s - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0204\n",
      "Epoch 23/30\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 24/30\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 26/30\n",
      "138/138 - 3s - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 27/30\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 29/30\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 30/30\n",
      "138/138 - 3s - loss: 0.0185 - val_loss: 0.0203\n",
      "final_val_loss =  0.01271046783829347\n",
      "_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-\n",
      "*************************   0   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0440 - val_loss: 0.0251\n",
      "Epoch 2/30\n",
      "138/138 - 3s - loss: 0.0255 - val_loss: 0.0232\n",
      "Epoch 3/30\n",
      "138/138 - 3s - loss: 0.0239 - val_loss: 0.0222\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0227 - val_loss: 0.0222\n",
      "Epoch 5/30\n",
      "138/138 - 3s - loss: 0.0221 - val_loss: 0.0216\n",
      "Epoch 6/30\n",
      "138/138 - 4s - loss: 0.0216 - val_loss: 0.0210\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0212 - val_loss: 0.0215\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 9/30\n",
      "138/138 - 4s - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 10/30\n",
      "138/138 - 4s - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0201 - val_loss: 0.0209\n",
      "Epoch 12/30\n",
      "138/138 - 3s - loss: 0.0199 - val_loss: 0.0205\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 4s - loss: 0.0197 - val_loss: 0.0204\n",
      "Epoch 14/30\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 15/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 16/30\n",
      "138/138 - 4s - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 19/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 21/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 22/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 24/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 25/30\n",
      "138/138 - 3s - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 4s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 27/30\n",
      "138/138 - 4s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 28/30\n",
      "138/138 - 3s - loss: 0.0188 - val_loss: 0.0202\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "138/138 - 5s - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 30/30\n",
      "138/138 - 3s - loss: 0.0188 - val_loss: 0.0202\n",
      "final_val_loss =  0.012758797121943158\n",
      "*************************   1   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0427 - val_loss: 0.0254\n",
      "Epoch 2/30\n",
      "138/138 - 3s - loss: 0.0254 - val_loss: 0.0232\n",
      "Epoch 3/30\n",
      "138/138 - 4s - loss: 0.0239 - val_loss: 0.0228\n",
      "Epoch 4/30\n",
      "138/138 - 4s - loss: 0.0229 - val_loss: 0.0220\n",
      "Epoch 5/30\n",
      "138/138 - 3s - loss: 0.0221 - val_loss: 0.0214\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0216\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 9/30\n",
      "138/138 - 4s - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 10/30\n",
      "138/138 - 3s - loss: 0.0204 - val_loss: 0.0206\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0201 - val_loss: 0.0209\n",
      "Epoch 12/30\n",
      "138/138 - 4s - loss: 0.0199 - val_loss: 0.0204\n",
      "Epoch 13/30\n",
      "138/138 - 3s - loss: 0.0197 - val_loss: 0.0204\n",
      "Epoch 14/30\n",
      "138/138 - 4s - loss: 0.0195 - val_loss: 0.0203\n",
      "Epoch 15/30\n",
      "138/138 - 4s - loss: 0.0193 - val_loss: 0.0202\n",
      "Epoch 16/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 17/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0204\n",
      "Epoch 19/30\n",
      "138/138 - 3s - loss: 0.0181 - val_loss: 0.0203\n",
      "Epoch 20/30\n",
      "138/138 - 3s - loss: 0.0180 - val_loss: 0.0203\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0180 - val_loss: 0.0203\n",
      "Epoch 22/30\n",
      "138/138 - 3s - loss: 0.0179 - val_loss: 0.0203\n",
      "Epoch 23/30\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0203\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0179 - val_loss: 0.0203\n",
      "Epoch 25/30\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0203\n",
      "Epoch 26/30\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0203\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0203\n",
      "Epoch 28/30\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0203\n",
      "Epoch 29/30\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0203\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0178 - val_loss: 0.0203\n",
      "final_val_loss =  0.012814425105500007\n",
      "*************************   2   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0452 - val_loss: 0.0251\n",
      "Epoch 2/30\n",
      "138/138 - 3s - loss: 0.0255 - val_loss: 0.0232\n",
      "Epoch 3/30\n",
      "138/138 - 3s - loss: 0.0239 - val_loss: 0.0227\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0229 - val_loss: 0.0225\n",
      "Epoch 5/30\n",
      "138/138 - 4s - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0213 - val_loss: 0.0216\n",
      "Epoch 8/30\n",
      "138/138 - 4s - loss: 0.0209 - val_loss: 0.0212\n",
      "Epoch 9/30\n",
      "138/138 - 4s - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 10/30\n",
      "138/138 - 3s - loss: 0.0205 - val_loss: 0.0208\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0202 - val_loss: 0.0207\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0200 - val_loss: 0.0207\n",
      "Epoch 13/30\n",
      "138/138 - 4s - loss: 0.0196 - val_loss: 0.0205\n",
      "Epoch 14/30\n",
      "138/138 - 3s - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 15/30\n",
      "138/138 - 4s - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 4s - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 17/30\n",
      "138/138 - 4s - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 18/30\n",
      "138/138 - 4s - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 20/30\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 21/30\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 23/30\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 24/30\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 26/30\n",
      "138/138 - 4s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 27/30\n",
      "138/138 - 4s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "138/138 - 4s - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 29/30\n",
      "138/138 - 3s - loss: 0.0192 - val_loss: 0.0204\n",
      "Epoch 30/30\n",
      "138/138 - 4s - loss: 0.0192 - val_loss: 0.0204\n",
      "final_val_loss =  0.012874474884087779\n",
      "*************************   3   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0432 - val_loss: 0.0252\n",
      "Epoch 2/30\n",
      "138/138 - 4s - loss: 0.0253 - val_loss: 0.0235\n",
      "Epoch 3/30\n",
      "138/138 - 4s - loss: 0.0237 - val_loss: 0.0230\n",
      "Epoch 4/30\n",
      "138/138 - 3s - loss: 0.0227 - val_loss: 0.0220\n",
      "Epoch 5/30\n",
      "138/138 - 3s - loss: 0.0221 - val_loss: 0.0223\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0216 - val_loss: 0.0224\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0212 - val_loss: 0.0218\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0209 - val_loss: 0.0213\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0206 - val_loss: 0.0210\n",
      "Epoch 10/30\n",
      "138/138 - 3s - loss: 0.0203 - val_loss: 0.0210\n",
      "Epoch 11/30\n",
      "138/138 - 4s - loss: 0.0202 - val_loss: 0.0209\n",
      "Epoch 12/30\n",
      "138/138 - 4s - loss: 0.0199 - val_loss: 0.0207\n",
      "Epoch 13/30\n",
      "138/138 - 4s - loss: 0.0196 - val_loss: 0.0206\n",
      "Epoch 14/30\n",
      "138/138 - 3s - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 15/30\n",
      "138/138 - 4s - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0208\n",
      "Epoch 17/30\n",
      "138/138 - 3s - loss: 0.0186 - val_loss: 0.0205\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0184 - val_loss: 0.0205\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0205\n",
      "Epoch 20/30\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0205\n",
      "Epoch 21/30\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0206\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 23/30\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 24/30\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 26/30\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 27/30\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0183 - val_loss: 0.0205\n",
      "Epoch 29/30\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 30/30\n",
      "138/138 - 3s - loss: 0.0182 - val_loss: 0.0205\n",
      "final_val_loss =  0.012936581788394236\n",
      "*************************   4   *************************\n",
      "Epoch 1/30\n",
      "138/138 - 5s - loss: 0.0431 - val_loss: 0.0249\n",
      "Epoch 2/30\n",
      "138/138 - 3s - loss: 0.0254 - val_loss: 0.0235\n",
      "Epoch 3/30\n",
      "138/138 - 3s - loss: 0.0239 - val_loss: 0.0225\n",
      "Epoch 4/30\n",
      "138/138 - 4s - loss: 0.0228 - val_loss: 0.0223\n",
      "Epoch 5/30\n",
      "138/138 - 4s - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 6/30\n",
      "138/138 - 3s - loss: 0.0217 - val_loss: 0.0213\n",
      "Epoch 7/30\n",
      "138/138 - 3s - loss: 0.0213 - val_loss: 0.0214\n",
      "Epoch 8/30\n",
      "138/138 - 3s - loss: 0.0210 - val_loss: 0.0214\n",
      "Epoch 9/30\n",
      "138/138 - 3s - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 10/30\n",
      "138/138 - 4s - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 11/30\n",
      "138/138 - 3s - loss: 0.0202 - val_loss: 0.0209\n",
      "Epoch 12/30\n",
      "138/138 - 3s - loss: 0.0199 - val_loss: 0.0204\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "138/138 - 3s - loss: 0.0197 - val_loss: 0.0205\n",
      "Epoch 14/30\n",
      "138/138 - 4s - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 15/30\n",
      "138/138 - 4s - loss: 0.0192 - val_loss: 0.0204\n",
      "Epoch 16/30\n",
      "138/138 - 3s - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "138/138 - 4s - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 18/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 19/30\n",
      "138/138 - 3s - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 21/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 22/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 24/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 25/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 27/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 28/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 30/30\n",
      "138/138 - 3s - loss: 0.0189 - val_loss: 0.0203\n",
      "final_val_loss =  0.01279973563590696\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [1903, 1881, 1589]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "for seed in SEED:\n",
    "    print('_-'*50)\n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:34.935430Z",
     "iopub.status.busy": "2020-11-10T20:09:34.934240Z",
     "iopub.status.idle": "2020-11-10T20:09:36.963110Z",
     "shell.execute_reply": "2020-11-10T20:09:36.962211Z"
    },
    "papermill": {
     "duration": 2.575692,
     "end_time": "2020-11-10T20:09:36.963228",
     "exception": false,
     "start_time": "2020-11-10T20:09:34.387536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23809</th>\n",
       "      <td>id_fffb1ceed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23810</th>\n",
       "      <td>id_fffb70c0c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>id_fffc1c3f4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>id_fffcb9e7c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>id_ffffdd77b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23814 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0      id_000644bb2                            0                       0   \n",
       "1      id_000779bfc                            0                       0   \n",
       "2      id_000a6266a                            0                       0   \n",
       "3      id_0015fd391                            0                       0   \n",
       "4      id_001626bd3                            0                       0   \n",
       "...             ...                          ...                     ...   \n",
       "23809  id_fffb1ceed                            0                       0   \n",
       "23810  id_fffb70c0c                            0                       0   \n",
       "23811  id_fffc1c3f4                            0                       0   \n",
       "23812  id_fffcb9e7c                            0                       0   \n",
       "23813  id_ffffdd77b                            0                       0   \n",
       "\n",
       "       acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0                   0                               0   \n",
       "1                   0                               0   \n",
       "2                   0                               0   \n",
       "3                   0                               0   \n",
       "4                   0                               0   \n",
       "...               ...                             ...   \n",
       "23809               0                               0   \n",
       "23810               0                               0   \n",
       "23811               0                               0   \n",
       "23812               0                               0   \n",
       "23813               0                               0   \n",
       "\n",
       "       acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                                      0                               0   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               0   \n",
       "...                                  ...                             ...   \n",
       "23809                                  0                               0   \n",
       "23810                                  0                               0   \n",
       "23811                                  0                               0   \n",
       "23812                                  0                               0   \n",
       "23813                                  0                               0   \n",
       "\n",
       "       adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                               0                              0   \n",
       "1                               0                              0   \n",
       "2                               0                              0   \n",
       "3                               0                              0   \n",
       "4                               0                              0   \n",
       "...                           ...                            ...   \n",
       "23809                           0                              0   \n",
       "23810                           0                              0   \n",
       "23811                           0                              0   \n",
       "23812                           0                              0   \n",
       "23813                           0                              0   \n",
       "\n",
       "       adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                               0  ...                                      0   \n",
       "1                               0  ...                                      0   \n",
       "2                               0  ...                                      0   \n",
       "3                               0  ...                                      0   \n",
       "4                               0  ...                                      0   \n",
       "...                           ...  ...                                    ...   \n",
       "23809                           0  ...                                      0   \n",
       "23810                           0  ...                                      0   \n",
       "23811                           0  ...                                      0   \n",
       "23812                           0  ...                                      0   \n",
       "23813                           0  ...                                      0   \n",
       "\n",
       "       trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0                 0                0                  0   \n",
       "1                 0                0                  0   \n",
       "2                 0                0                  0   \n",
       "3                 0                0                  0   \n",
       "4                 0                0                  0   \n",
       "...             ...              ...                ...   \n",
       "23809             0                0                  0   \n",
       "23810             0                0                  0   \n",
       "23811             0                0                  0   \n",
       "23812             0                0                  0   \n",
       "23813             0                0                  0   \n",
       "\n",
       "       tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "...                          ...                                    ...   \n",
       "23809                          0                                      0   \n",
       "23810                          0                                      0   \n",
       "23811                          0                                      0   \n",
       "23812                          0                                      0   \n",
       "23813                          0                                      0   \n",
       "\n",
       "       vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0                    0          0                           0              0  \n",
       "1                    0          0                           0              0  \n",
       "2                    0          0                           0              0  \n",
       "3                    0          0                           0              0  \n",
       "4                    0          0                           0              0  \n",
       "...                ...        ...                         ...            ...  \n",
       "23809                0          0                           0              0  \n",
       "23810                0          0                           0              0  \n",
       "23811                0          0                           0              0  \n",
       "23812                0          0                           0              0  \n",
       "23813                0          0                           0              0  \n",
       "\n",
       "[23814 rows x 207 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions\n",
    "train_targets_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:38.031573Z",
     "iopub.status.busy": "2020-11-10T20:09:38.030789Z",
     "iopub.status.idle": "2020-11-10T20:09:38.034007Z",
     "shell.execute_reply": "2020-11-10T20:09:38.034562Z"
    },
    "papermill": {
     "duration": 0.534401,
     "end_time": "2020-11-10T20:09:38.034706",
     "exception": false,
     "start_time": "2020-11-10T20:09:37.500305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:39.820442Z",
     "iopub.status.busy": "2020-11-10T20:09:39.818980Z",
     "iopub.status.idle": "2020-11-10T20:09:40.864118Z",
     "shell.execute_reply": "2020-11-10T20:09:40.864982Z"
    },
    "papermill": {
     "duration": 1.950265,
     "end_time": "2020-11-10T20:09:40.865131",
     "exception": false,
     "start_time": "2020-11-10T20:09:38.914866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss:  0.015235661930444814\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "scores = []\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / 206\n",
    "    scores += [score_]\n",
    "print(\"CV log_loss: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:41.929731Z",
     "iopub.status.busy": "2020-11-10T20:09:41.928542Z",
     "iopub.status.idle": "2020-11-10T20:09:41.932585Z",
     "shell.execute_reply": "2020-11-10T20:09:41.933188Z"
    },
    "papermill": {
     "duration": 0.533551,
     "end_time": "2020-11-10T20:09:41.933329",
     "exception": false,
     "start_time": "2020-11-10T20:09:41.399778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.89488905e-03, 1.81573591e-03, 8.27887561e-04, ...,\n",
       "        1.82216855e-03, 3.96363685e-04, 1.91453530e-03],\n",
       "       [9.05837495e-04, 8.61874646e-04, 2.64176517e-03, ...,\n",
       "        4.08756190e-03, 2.50380979e-03, 2.21275282e-03],\n",
       "       [1.12464230e-03, 2.51728599e-03, 8.13891044e-04, ...,\n",
       "        8.68467245e-04, 2.45445131e-04, 1.14595527e-03],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.88304874e-05, 1.26507269e-04, 8.06385300e-05, ...,\n",
       "        1.24708378e-04, 2.52887352e-04, 3.62131007e-04],\n",
       "       [4.20663528e-04, 1.01286949e-03, 1.14669255e-03, ...,\n",
       "        6.60082083e-04, 2.53098066e-03, 1.72177807e-04]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:43.059728Z",
     "iopub.status.busy": "2020-11-10T20:09:43.058620Z",
     "iopub.status.idle": "2020-11-10T20:09:43.267537Z",
     "shell.execute_reply": "2020-11-10T20:09:43.268070Z"
    },
    "papermill": {
     "duration": 0.744383,
     "end_time": "2020-11-10T20:09:43.268210",
     "exception": false,
     "start_time": "2020-11-10T20:09:42.523827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f05db40b150>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:44.623813Z",
     "iopub.status.busy": "2020-11-10T20:09:44.622850Z",
     "iopub.status.idle": "2020-11-10T20:09:44.628238Z",
     "shell.execute_reply": "2020-11-10T20:09:44.628681Z"
    },
    "papermill": {
     "duration": 0.706237,
     "end_time": "2020-11-10T20:09:44.628811",
     "exception": false,
     "start_time": "2020-11-10T20:09:43.922574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = []\n",
    "for i in range(len(scores)):\n",
    "    if scores[i] > 0.02:\n",
    "        #print(i)\n",
    "        s+=[target_cols[i]]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.574908,
     "end_time": "2020-11-10T20:09:45.743897",
     "exception": false,
     "start_time": "2020-11-10T20:09:45.168989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:46.859496Z",
     "iopub.status.busy": "2020-11-10T20:09:46.858650Z",
     "iopub.status.idle": "2020-11-10T20:09:46.861901Z",
     "shell.execute_reply": "2020-11-10T20:09:46.861366Z"
    },
    "papermill": {
     "duration": 0.584146,
     "end_time": "2020-11-10T20:09:46.862055",
     "exception": false,
     "start_time": "2020-11-10T20:09:46.277909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_1 = [\n",
    "    '5-alpha_reductase_inhibitor',\n",
    "    '11-beta-hsd1_inhibitor',\n",
    "    'adenylyl_cyclase_activator',\n",
    "    'aldehyde_dehydrogenase_inhibitor',\n",
    "    'ampk_activator',\n",
    "    'analgesic',\n",
    "    'antiarrhythmic',\n",
    "    'anticonvulsant',\n",
    "    'antifungal',\n",
    "    'antihistamine',\n",
    "    'antimalarial',\n",
    "    'antiviral',\n",
    "    'atm_kinase_inhibitor',\n",
    "    'atp-sensitive_potassium_channel_antagonist',\n",
    "    'atp_synthase_inhibitor',\n",
    "    'atr_kinase_inhibitor',\n",
    "    'autotaxin_inhibitor',\n",
    "    'bacterial_membrane_integrity_inhibitor',\n",
    "    'calcineurin_inhibitor',\n",
    "    'caspase_activator',\n",
    "    'catechol_o_methyltransferase_inhibitor',\n",
    "    'cck_receptor_antagonist',\n",
    "    'chk_inhibitor',\n",
    "    'coagulation_factor_inhibitor',\n",
    "    'diuretic',\n",
    "    'elastase_inhibitor',\n",
    "    'erbb2_inhibitor',\n",
    "    'farnesyltransferase_inhibitor',\n",
    "    'focal_adhesion_kinase_inhibitor',\n",
    "    'free_radical_scavenger',\n",
    "    'fungal_squalene_epoxidase_inhibitor',\n",
    "    'glutamate_inhibitor',\n",
    "    'gonadotropin_receptor_agonist',\n",
    "    'histone_lysine_demethylase_inhibitor',\n",
    "    'hsp_inhibitor',\n",
    "    'ikk_inhibitor',\n",
    "    'laxative',\n",
    "    'leukotriene_inhibitor',\n",
    "    'lipase_inhibitor',\n",
    "    'lxr_agonist',\n",
    "    'mdm_inhibitor',\n",
    "    'monoacylglycerol_lipase_inhibitor',\n",
    "    'monopolar_spindle_1_kinase_inhibitor',\n",
    "    'nicotinic_receptor_agonist',\n",
    "    'nitric_oxide_production_inhibitor',\n",
    "    'norepinephrine_reuptake_inhibitor',\n",
    "    'nrf2_activator',\n",
    "    'pdk_inhibitor',\n",
    "    'progesterone_receptor_antagonist',\n",
    "    'proteasome_inhibitor',\n",
    "    'protein_phosphatase_inhibitor',\n",
    "    'protein_tyrosine_kinase_inhibitor',\n",
    "    'ras_gtpase_inhibitor',\n",
    "    'retinoid_receptor_antagonist',\n",
    "    'steroid',\n",
    "    'syk_inhibitor',\n",
    "    'tgf-beta_receptor_inhibitor',\n",
    "    'thrombin_inhibitor',\n",
    "    'tlr_antagonist',\n",
    "    'transient_receptor_potential_channel_antagonist',\n",
    "    'tropomyosin_receptor_kinase_inhibitor',\n",
    "    'trpv_agonist',\n",
    "    'ubiquitin_specific_protease_inhibitor',\n",
    "    'vitamin_d_receptor_agonist'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:47.999461Z",
     "iopub.status.busy": "2020-11-10T20:09:47.998611Z",
     "iopub.status.idle": "2020-11-10T20:09:48.062580Z",
     "shell.execute_reply": "2020-11-10T20:09:48.061612Z"
    },
    "papermill": {
     "duration": 0.658992,
     "end_time": "2020-11-10T20:09:48.062705",
     "exception": false,
     "start_time": "2020-11-10T20:09:47.403713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "\n",
    "params_1 = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'boost_from_average': True,\n",
    "    'num_threads': 4,\n",
    "    'random_state': 42,\n",
    "    \n",
    "    'learning_rate': 0.01,\n",
    "    \n",
    "    # from Optuna result in Version 7\n",
    "    'num_leaves': 212,\n",
    "    'min_data_in_leaf': 92,\n",
    "    'min_child_weight': 0.0010123391323415569,\n",
    "    'max_depth': 35,\n",
    "    'bagging_fraction': 0.7968351296815959,\n",
    "    'feature_fraction': 0.7556374471450119,\n",
    "    'lambda_l1': 0.23497601594060086,\n",
    "    'lambda_l2': 0.15889208239516134\n",
    "}\n",
    "params_2 = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'boost_from_average': True,\n",
    "    'num_threads': 4,\n",
    "    'random_state': 42,\n",
    "    \n",
    "    'learning_rate': 0.01,\n",
    "    \n",
    "    # from Optuna result in Version 15\n",
    "    'num_leaves': 106,\n",
    "    'min_data_in_leaf': 176,\n",
    "    'min_child_weight': 0.08961015929882983,\n",
    "    'max_depth': 3,\n",
    "    'bagging_fraction': 0.5672004837454858,\n",
    "    'feature_fraction': 0.611628226420641,\n",
    "    'lambda_l1': 1.293005852529098,\n",
    "    'lambda_l2': 1.6012450757049599\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:49.234041Z",
     "iopub.status.busy": "2020-11-10T20:09:49.226145Z",
     "iopub.status.idle": "2020-11-10T20:09:49.236751Z",
     "shell.execute_reply": "2020-11-10T20:09:49.237241Z"
    },
    "papermill": {
     "duration": 0.598594,
     "end_time": "2020-11-10T20:09:49.237383",
     "exception": false,
     "start_time": "2020-11-10T20:09:48.638789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "import pickle\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "\n",
    "def run_training_lgbm(fold, seed, col):\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train = process_data(folds)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "    \n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    x_train, y_train  = train_df[feature_cols].values, train_df[col].values\n",
    "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[col].values\n",
    "    x_test = test_[feature_cols].values\n",
    "    oof = np.zeros(len(train))\n",
    "    trn_data = lgb.Dataset(x_train, label=y_train)\n",
    "    val_data = lgb.Dataset(x_valid, label=y_valid)\n",
    "    if col in columns_1:\n",
    "        print('Params 1')\n",
    "        params = params_1\n",
    "    else:\n",
    "        print('Params 2')\n",
    "        params = params_2\n",
    "    clf = lgb.train(params, trn_data, 10000, valid_sets = [trn_data, val_data], verbose_eval=0, early_stopping_rounds=20)\n",
    "    oof_tr = clf.predict(x_train)\n",
    "    oof[val_idx] = clf.predict(x_valid)\n",
    "    predictions = clf.predict(x_test) \n",
    "    \n",
    "    print('loss = ', log_loss(y_train, oof_tr))\n",
    "    print('val_loss = ', log_loss(y_valid, oof[val_idx]))\n",
    "    \n",
    "    \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:50.717394Z",
     "iopub.status.busy": "2020-11-10T20:09:50.715827Z",
     "iopub.status.idle": "2020-11-10T20:09:50.719367Z",
     "shell.execute_reply": "2020-11-10T20:09:50.720068Z"
    },
    "papermill": {
     "duration": 0.594897,
     "end_time": "2020-11-10T20:09:50.720216",
     "exception": false,
     "start_time": "2020-11-10T20:09:50.125319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_k_fold_lgbm(NFOLDS, seed, col):\n",
    "    oof = np.zeros(len(train))\n",
    "    predictions = np.zeros(len(test))\n",
    "    \n",
    "    for fold in range(NFOLDS):\n",
    "        print('*'*25,' ',fold,' ','*'*25)\n",
    "        oof_, pred_ = run_training_lgbm(fold, seed, col)\n",
    "        \n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-10T20:09:51.800625Z",
     "iopub.status.busy": "2020-11-10T20:09:51.799613Z",
     "iopub.status.idle": "2020-11-11T01:23:25.892883Z",
     "shell.execute_reply": "2020-11-11T01:23:25.892177Z"
    },
    "papermill": {
     "duration": 18814.639879,
     "end_time": "2020-11-11T01:23:25.893078",
     "exception": false,
     "start_time": "2020-11-10T20:09:51.253199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++   0   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.031039348094235853\n",
      "val_loss =  0.046164243414958374\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.04037551908736329\n",
      "val_loss =  0.04781954842919325\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.043972764280322506\n",
      "val_loss =  0.048653626053162854\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.043309414245719054\n",
      "val_loss =  0.04823142095406188\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04002036947300984\n",
      "val_loss =  0.04838081178133611\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.031039348094235853\n",
      "val_loss =  0.046164243414958374\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.04037551908736329\n",
      "val_loss =  0.04781954842919325\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.043972764280322506\n",
      "val_loss =  0.048653626053162854\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.043309414245719054\n",
      "val_loss =  0.04823142095406188\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04002036947300984\n",
      "val_loss =  0.04838081178133611\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.031039348094235853\n",
      "val_loss =  0.046164243414958374\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.04037551908736329\n",
      "val_loss =  0.04781954842919325\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.043972764280322506\n",
      "val_loss =  0.048653626053162854\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.043309414245719054\n",
      "val_loss =  0.04823142095406188\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04002036947300984\n",
      "val_loss =  0.04838081178133611\n",
      "+++++++++++++++++++++++++   1   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.0606906072313799\n",
      "val_loss =  0.06949071489848532\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05975428440173123\n",
      "val_loss =  0.06933651637109106\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.06310149227178898\n",
      "val_loss =  0.07039093147625863\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.06160754052707931\n",
      "val_loss =  0.07177343499369884\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.06280790740235147\n",
      "val_loss =  0.07098809196646647\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.0606906072313799\n",
      "val_loss =  0.06949071489848532\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05975428440173123\n",
      "val_loss =  0.06933651637109106\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.06310149227178898\n",
      "val_loss =  0.07039093147625863\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.06160754052707931\n",
      "val_loss =  0.07177343499369884\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.06280790740235147\n",
      "val_loss =  0.07098809196646647\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.0606906072313799\n",
      "val_loss =  0.06949071489848532\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05975428440173123\n",
      "val_loss =  0.06933651637109106\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.06310149227178898\n",
      "val_loss =  0.07039093147625863\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.06160754052707931\n",
      "val_loss =  0.07177343499369884\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.06280790740235147\n",
      "val_loss =  0.07098809196646647\n",
      "+++++++++++++++++++++++++   2   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02409127841419375\n",
      "val_loss =  0.027407304637457736\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02145255054729705\n",
      "val_loss =  0.027512842974125623\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.021595465768278217\n",
      "val_loss =  0.02655442299027442\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.02267991851248251\n",
      "val_loss =  0.02756763005389672\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.018825964389946086\n",
      "val_loss =  0.027433732042601133\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02409127841419375\n",
      "val_loss =  0.027407304637457736\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02145255054729705\n",
      "val_loss =  0.027512842974125623\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.021595465768278217\n",
      "val_loss =  0.02655442299027442\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.02267991851248251\n",
      "val_loss =  0.02756763005389672\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.018825964389946086\n",
      "val_loss =  0.027433732042601133\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02409127841419375\n",
      "val_loss =  0.027407304637457736\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02145255054729705\n",
      "val_loss =  0.027512842974125623\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.021595465768278217\n",
      "val_loss =  0.02655442299027442\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.02267991851248251\n",
      "val_loss =  0.02756763005389672\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.018825964389946086\n",
      "val_loss =  0.027433732042601133\n",
      "+++++++++++++++++++++++++   3   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.04416001994741301\n",
      "val_loss =  0.06066684736824972\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.03305650989061362\n",
      "val_loss =  0.056990922970659684\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.049850365688746325\n",
      "val_loss =  0.062699796315838\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.03908648001577848\n",
      "val_loss =  0.060162225125874526\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.0454773228264476\n",
      "val_loss =  0.06290641843921849\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.04416001994741301\n",
      "val_loss =  0.06066684736824972\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.03305650989061362\n",
      "val_loss =  0.056990922970659684\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.049850365688746325\n",
      "val_loss =  0.062699796315838\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.03908648001577848\n",
      "val_loss =  0.060162225125874526\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.0454773228264476\n",
      "val_loss =  0.06290641843921849\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.04416001994741301\n",
      "val_loss =  0.06066684736824972\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.03305650989061362\n",
      "val_loss =  0.056990922970659684\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.049850365688746325\n",
      "val_loss =  0.062699796315838\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.03908648001577848\n",
      "val_loss =  0.060162225125874526\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.0454773228264476\n",
      "val_loss =  0.06290641843921849\n",
      "+++++++++++++++++++++++++   4   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.07353225527528406\n",
      "val_loss =  0.08173174731262861\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.06876583998370499\n",
      "val_loss =  0.08034251398608586\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0696267104246777\n",
      "val_loss =  0.0802041160021007\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.07664122173866618\n",
      "val_loss =  0.08253042171220763\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.07461921083084984\n",
      "val_loss =  0.08246498602894384\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.07353225527528406\n",
      "val_loss =  0.08173174731262861\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.06876583998370499\n",
      "val_loss =  0.08034251398608586\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0696267104246777\n",
      "val_loss =  0.0802041160021007\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.07664122173866618\n",
      "val_loss =  0.08253042171220763\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.07461921083084984\n",
      "val_loss =  0.08246498602894384\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.07353225527528406\n",
      "val_loss =  0.08173174731262861\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.06876583998370499\n",
      "val_loss =  0.08034251398608586\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0696267104246777\n",
      "val_loss =  0.0802041160021007\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.07664122173866618\n",
      "val_loss =  0.08253042171220763\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.07461921083084984\n",
      "val_loss =  0.08246498602894384\n",
      "+++++++++++++++++++++++++   5   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01795652504393219\n",
      "val_loss =  0.025857295169648114\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.026097951514238528\n",
      "val_loss =  0.025373312322305674\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0179383030997654\n",
      "val_loss =  0.026148945111995548\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.023591155042461367\n",
      "val_loss =  0.026438066214438914\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.02145002892506094\n",
      "val_loss =  0.026136889072171324\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01795652504393219\n",
      "val_loss =  0.025857295169648114\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.026097951514238528\n",
      "val_loss =  0.025373312322305674\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0179383030997654\n",
      "val_loss =  0.026148945111995548\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.023591155042461367\n",
      "val_loss =  0.026438066214438914\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.02145002892506094\n",
      "val_loss =  0.026136889072171324\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01795652504393219\n",
      "val_loss =  0.025857295169648114\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.026097951514238528\n",
      "val_loss =  0.025373312322305674\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0179383030997654\n",
      "val_loss =  0.026148945111995548\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.023591155042461367\n",
      "val_loss =  0.026438066214438914\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.02145002892506094\n",
      "val_loss =  0.026136889072171324\n",
      "+++++++++++++++++++++++++   6   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.022066234106197537\n",
      "val_loss =  0.0239620055948368\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.014684894375145741\n",
      "val_loss =  0.022989052556530935\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.02211425569155117\n",
      "val_loss =  0.02399131348027625\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.0202346014726478\n",
      "val_loss =  0.023748837151463285\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01991742799693334\n",
      "val_loss =  0.023823350749215665\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.022066234106197537\n",
      "val_loss =  0.0239620055948368\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.014684894375145741\n",
      "val_loss =  0.022989052556530935\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.02211425569155117\n",
      "val_loss =  0.02399131348027625\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.0202346014726478\n",
      "val_loss =  0.023748837151463285\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01991742799693334\n",
      "val_loss =  0.023823350749215665\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.022066234106197537\n",
      "val_loss =  0.0239620055948368\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.014684894375145741\n",
      "val_loss =  0.022989052556530935\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.02211425569155117\n",
      "val_loss =  0.02399131348027625\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.0202346014726478\n",
      "val_loss =  0.023748837151463285\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01991742799693334\n",
      "val_loss =  0.023823350749215665\n",
      "+++++++++++++++++++++++++   7   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.014348947762392657\n",
      "val_loss =  0.02242535717501207\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.009263031580655374\n",
      "val_loss =  0.01945925252753905\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.010179435251401003\n",
      "val_loss =  0.02231839722889302\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.012592261666185892\n",
      "val_loss =  0.024585276599754114\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.013580672031373135\n",
      "val_loss =  0.024797144842552663\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.014348947762392657\n",
      "val_loss =  0.02242535717501207\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.009263031580655374\n",
      "val_loss =  0.01945925252753905\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.010179435251401003\n",
      "val_loss =  0.02231839722889302\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.012592261666185892\n",
      "val_loss =  0.024585276599754114\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.013580672031373135\n",
      "val_loss =  0.024797144842552663\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.014348947762392657\n",
      "val_loss =  0.02242535717501207\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.009263031580655374\n",
      "val_loss =  0.01945925252753905\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.010179435251401003\n",
      "val_loss =  0.02231839722889302\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.012592261666185892\n",
      "val_loss =  0.024585276599754114\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.013580672031373135\n",
      "val_loss =  0.024797144842552663\n",
      "+++++++++++++++++++++++++   8   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01513312208957391\n",
      "val_loss =  0.023440281813937015\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02343341753675619\n",
      "val_loss =  0.024066419498547518\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.01805354345716118\n",
      "val_loss =  0.02347836451932466\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.015691302996090995\n",
      "val_loss =  0.023453098652082123\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.018772256092794308\n",
      "val_loss =  0.02367902243430098\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01513312208957391\n",
      "val_loss =  0.023440281813937015\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02343341753675619\n",
      "val_loss =  0.024066419498547518\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.01805354345716118\n",
      "val_loss =  0.02347836451932466\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.015691302996090995\n",
      "val_loss =  0.023453098652082123\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.018772256092794308\n",
      "val_loss =  0.02367902243430098\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01513312208957391\n",
      "val_loss =  0.023440281813937015\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02343341753675619\n",
      "val_loss =  0.024066419498547518\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.01805354345716118\n",
      "val_loss =  0.02347836451932466\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.015691302996090995\n",
      "val_loss =  0.023453098652082123\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.018772256092794308\n",
      "val_loss =  0.02367902243430098\n",
      "+++++++++++++++++++++++++   9   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.04329142429891674\n",
      "val_loss =  0.04878622675119671\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.0367867698734123\n",
      "val_loss =  0.047114617770765525\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.03706805679330922\n",
      "val_loss =  0.04973656004791809\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.045011700327335896\n",
      "val_loss =  0.04897389700230627\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04462824779607672\n",
      "val_loss =  0.050233434393205295\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.04329142429891674\n",
      "val_loss =  0.04878622675119671\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.0367867698734123\n",
      "val_loss =  0.047114617770765525\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.03706805679330922\n",
      "val_loss =  0.04973656004791809\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.045011700327335896\n",
      "val_loss =  0.04897389700230627\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04462824779607672\n",
      "val_loss =  0.050233434393205295\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.04329142429891674\n",
      "val_loss =  0.04878622675119671\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.0367867698734123\n",
      "val_loss =  0.047114617770765525\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.03706805679330922\n",
      "val_loss =  0.04973656004791809\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.045011700327335896\n",
      "val_loss =  0.04897389700230627\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04462824779607672\n",
      "val_loss =  0.050233434393205295\n",
      "+++++++++++++++++++++++++   10   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02318519479106668\n",
      "val_loss =  0.026279907093304536\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02075627132952552\n",
      "val_loss =  0.02468273877251533\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.021367399618544194\n",
      "val_loss =  0.025924563427517665\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.024657767177980888\n",
      "val_loss =  0.026522368490296783\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.021341160506528\n",
      "val_loss =  0.02613064868929902\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02318519479106668\n",
      "val_loss =  0.026279907093304536\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02075627132952552\n",
      "val_loss =  0.02468273877251533\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.021367399618544194\n",
      "val_loss =  0.025924563427517665\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.024657767177980888\n",
      "val_loss =  0.026522368490296783\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.021341160506528\n",
      "val_loss =  0.02613064868929902\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02318519479106668\n",
      "val_loss =  0.026279907093304536\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02075627132952552\n",
      "val_loss =  0.02468273877251533\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.021367399618544194\n",
      "val_loss =  0.025924563427517665\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.024657767177980888\n",
      "val_loss =  0.026522368490296783\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.021341160506528\n",
      "val_loss =  0.02613064868929902\n",
      "+++++++++++++++++++++++++   11   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.024328251005104832\n",
      "val_loss =  0.03201902929699335\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02079907002851968\n",
      "val_loss =  0.03149821658686573\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.017693007842898133\n",
      "val_loss =  0.03018931968464466\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.026349992680543128\n",
      "val_loss =  0.03185349727815922\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.015589361402579868\n",
      "val_loss =  0.031022566872746713\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.024328251005104832\n",
      "val_loss =  0.03201902929699335\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02079907002851968\n",
      "val_loss =  0.03149821658686573\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.017693007842898133\n",
      "val_loss =  0.03018931968464466\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.026349992680543128\n",
      "val_loss =  0.03185349727815922\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.015589361402579868\n",
      "val_loss =  0.031022566872746713\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.024328251005104832\n",
      "val_loss =  0.03201902929699335\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02079907002851968\n",
      "val_loss =  0.03149821658686573\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.017693007842898133\n",
      "val_loss =  0.03018931968464466\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.026349992680543128\n",
      "val_loss =  0.03185349727815922\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.015589361402579868\n",
      "val_loss =  0.031022566872746713\n",
      "+++++++++++++++++++++++++   12   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.05320047087502635\n",
      "val_loss =  0.06653455332964153\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05059354314574905\n",
      "val_loss =  0.06509679242779699\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05557536835584076\n",
      "val_loss =  0.06636266548619599\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.03629291532241286\n",
      "val_loss =  0.06498695242536535\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04947298564246214\n",
      "val_loss =  0.06498930074464632\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.05320047087502635\n",
      "val_loss =  0.06653455332964153\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05059354314574905\n",
      "val_loss =  0.06509679242779699\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05557536835584076\n",
      "val_loss =  0.06636266548619599\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.03629291532241286\n",
      "val_loss =  0.06498695242536535\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04947298564246214\n",
      "val_loss =  0.06498930074464632\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.05320047087502635\n",
      "val_loss =  0.06653455332964153\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05059354314574905\n",
      "val_loss =  0.06509679242779699\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05557536835584076\n",
      "val_loss =  0.06636266548619599\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.03629291532241286\n",
      "val_loss =  0.06498695242536535\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04947298564246214\n",
      "val_loss =  0.06498930074464632\n",
      "+++++++++++++++++++++++++   13   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.024608874967562464\n",
      "val_loss =  0.028809679264932095\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.024236786121903053\n",
      "val_loss =  0.028697184086901355\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.02846570134122387\n",
      "val_loss =  0.029015756459135844\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.029355323270115165\n",
      "val_loss =  0.030317860966423672\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.02590286880043335\n",
      "val_loss =  0.030073754011823998\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.024608874967562464\n",
      "val_loss =  0.028809679264932095\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.024236786121903053\n",
      "val_loss =  0.028697184086901355\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.02846570134122387\n",
      "val_loss =  0.029015756459135844\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.029355323270115165\n",
      "val_loss =  0.030317860966423672\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.02590286880043335\n",
      "val_loss =  0.030073754011823998\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.024608874967562464\n",
      "val_loss =  0.028809679264932095\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.024236786121903053\n",
      "val_loss =  0.028697184086901355\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.02846570134122387\n",
      "val_loss =  0.029015756459135844\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.029355323270115165\n",
      "val_loss =  0.030317860966423672\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.02590286880043335\n",
      "val_loss =  0.030073754011823998\n",
      "+++++++++++++++++++++++++   14   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.005987128200524243\n",
      "val_loss =  0.0189180552894415\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.0017850223001530164\n",
      "val_loss =  0.007284651381428671\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.008978858635228345\n",
      "val_loss =  0.023479032249803237\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.00972921485300044\n",
      "val_loss =  0.028055413514902098\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.006413615576192588\n",
      "val_loss =  0.026318288767592204\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.005987128200524243\n",
      "val_loss =  0.0189180552894415\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.0017850223001530164\n",
      "val_loss =  0.007284651381428671\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.008978858635228345\n",
      "val_loss =  0.023479032249803237\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.00972921485300044\n",
      "val_loss =  0.028055413514902098\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.006413615576192588\n",
      "val_loss =  0.026318288767592204\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.005987128200524243\n",
      "val_loss =  0.0189180552894415\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.0017850223001530164\n",
      "val_loss =  0.007284651381428671\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.008978858635228345\n",
      "val_loss =  0.023479032249803237\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.00972921485300044\n",
      "val_loss =  0.028055413514902098\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.006413615576192588\n",
      "val_loss =  0.026318288767592204\n",
      "+++++++++++++++++++++++++   15   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.08164329377698344\n",
      "val_loss =  0.09258880566605183\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.08108977844070989\n",
      "val_loss =  0.09354888950790682\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.07666225460626037\n",
      "val_loss =  0.09319174325535586\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.08131613761124208\n",
      "val_loss =  0.09396306468699774\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.07940164991920888\n",
      "val_loss =  0.09234977256250167\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.08164329377698344\n",
      "val_loss =  0.09258880566605183\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.08108977844070989\n",
      "val_loss =  0.09354888950790682\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.07666225460626037\n",
      "val_loss =  0.09319174325535586\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.08131613761124208\n",
      "val_loss =  0.09396306468699774\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.07940164991920888\n",
      "val_loss =  0.09234977256250167\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.08164329377698344\n",
      "val_loss =  0.09258880566605183\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.08108977844070989\n",
      "val_loss =  0.09354888950790682\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.07666225460626037\n",
      "val_loss =  0.09319174325535586\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.08131613761124208\n",
      "val_loss =  0.09396306468699774\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.07940164991920888\n",
      "val_loss =  0.09234977256250167\n",
      "+++++++++++++++++++++++++   16   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.022704000425146198\n",
      "val_loss =  0.029006464732602683\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.024399780624448447\n",
      "val_loss =  0.029788604081581203\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.020366531831069783\n",
      "val_loss =  0.02902412696161411\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.018649637564368576\n",
      "val_loss =  0.02814319200847586\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.025770315595843377\n",
      "val_loss =  0.0298963797519864\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.022704000425146198\n",
      "val_loss =  0.029006464732602683\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.024399780624448447\n",
      "val_loss =  0.029788604081581203\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.020366531831069783\n",
      "val_loss =  0.02902412696161411\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.018649637564368576\n",
      "val_loss =  0.02814319200847586\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.025770315595843377\n",
      "val_loss =  0.0298963797519864\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.022704000425146198\n",
      "val_loss =  0.029006464732602683\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.024399780624448447\n",
      "val_loss =  0.029788604081581203\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.020366531831069783\n",
      "val_loss =  0.02902412696161411\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.018649637564368576\n",
      "val_loss =  0.02814319200847586\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.025770315595843377\n",
      "val_loss =  0.0298963797519864\n",
      "+++++++++++++++++++++++++   17   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.05674896059802075\n",
      "val_loss =  0.08454012105148932\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.06380518585984091\n",
      "val_loss =  0.08302218251526315\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0609224685745145\n",
      "val_loss =  0.08691048419606975\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05459830349653248\n",
      "val_loss =  0.08037157655301486\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.056761538897269474\n",
      "val_loss =  0.08593314676109981\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.05674896059802075\n",
      "val_loss =  0.08454012105148932\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.06380518585984091\n",
      "val_loss =  0.08302218251526315\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0609224685745145\n",
      "val_loss =  0.08691048419606975\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05459830349653248\n",
      "val_loss =  0.08037157655301486\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.056761538897269474\n",
      "val_loss =  0.08593314676109981\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.05674896059802075\n",
      "val_loss =  0.08454012105148932\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.06380518585984091\n",
      "val_loss =  0.08302218251526315\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0609224685745145\n",
      "val_loss =  0.08691048419606975\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05459830349653248\n",
      "val_loss =  0.08037157655301486\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.056761538897269474\n",
      "val_loss =  0.08593314676109981\n",
      "+++++++++++++++++++++++++   18   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02443514831028911\n",
      "val_loss =  0.03271658849065219\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02917109062567439\n",
      "val_loss =  0.03331110979917464\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.031378569907370174\n",
      "val_loss =  0.03482874759058563\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.02976142590671137\n",
      "val_loss =  0.03312255292335609\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.023011209394762238\n",
      "val_loss =  0.032715203067695625\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02443514831028911\n",
      "val_loss =  0.03271658849065219\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02917109062567439\n",
      "val_loss =  0.03331110979917464\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.031378569907370174\n",
      "val_loss =  0.03482874759058563\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.02976142590671137\n",
      "val_loss =  0.03312255292335609\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.023011209394762238\n",
      "val_loss =  0.032715203067695625\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02443514831028911\n",
      "val_loss =  0.03271658849065219\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02917109062567439\n",
      "val_loss =  0.03331110979917464\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.031378569907370174\n",
      "val_loss =  0.03482874759058563\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.02976142590671137\n",
      "val_loss =  0.03312255292335609\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.023011209394762238\n",
      "val_loss =  0.032715203067695625\n",
      "+++++++++++++++++++++++++   19   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.06647406415966188\n",
      "val_loss =  0.08827113054710965\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.06811094939763951\n",
      "val_loss =  0.08870606477512083\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.07500023255282005\n",
      "val_loss =  0.08865260227949319\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.06933425966413068\n",
      "val_loss =  0.08719902090620864\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.05869082471205092\n",
      "val_loss =  0.08752084139774517\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.06647406415966188\n",
      "val_loss =  0.08827113054710965\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.06811094939763951\n",
      "val_loss =  0.08870606477512083\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.07500023255282005\n",
      "val_loss =  0.08865260227949319\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.06933425966413068\n",
      "val_loss =  0.08719902090620864\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.05869082471205092\n",
      "val_loss =  0.08752084139774517\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.06647406415966188\n",
      "val_loss =  0.08827113054710965\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.06811094939763951\n",
      "val_loss =  0.08870606477512083\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.07500023255282005\n",
      "val_loss =  0.08865260227949319\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.06933425966413068\n",
      "val_loss =  0.08719902090620864\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.05869082471205092\n",
      "val_loss =  0.08752084139774517\n",
      "+++++++++++++++++++++++++   20   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.017750384089281104\n",
      "val_loss =  0.03856519287981543\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.03910578646797161\n",
      "val_loss =  0.04254462002072768\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.03128296286613695\n",
      "val_loss =  0.041762283348197864\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.029658774892582666\n",
      "val_loss =  0.04043458198879523\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.030870737731667583\n",
      "val_loss =  0.040669616409447946\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.017750384089281104\n",
      "val_loss =  0.03856519287981543\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.03910578646797161\n",
      "val_loss =  0.04254462002072768\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.03128296286613695\n",
      "val_loss =  0.041762283348197864\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.029658774892582666\n",
      "val_loss =  0.04043458198879523\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.030870737731667583\n",
      "val_loss =  0.040669616409447946\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.017750384089281104\n",
      "val_loss =  0.03856519287981543\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.03910578646797161\n",
      "val_loss =  0.04254462002072768\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.03128296286613695\n",
      "val_loss =  0.041762283348197864\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.029658774892582666\n",
      "val_loss =  0.04043458198879523\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.030870737731667583\n",
      "val_loss =  0.040669616409447946\n",
      "+++++++++++++++++++++++++   21   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.00640280504799651\n",
      "val_loss =  0.02508304447459289\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.006536595403538293\n",
      "val_loss =  0.026161382150856602\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.00896656755660747\n",
      "val_loss =  0.02961205850567333\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.007120234787621506\n",
      "val_loss =  0.02700256582092052\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.005309304286339469\n",
      "val_loss =  0.024566376935597267\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.00640280504799651\n",
      "val_loss =  0.02508304447459289\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.006536595403538293\n",
      "val_loss =  0.026161382150856602\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.00896656755660747\n",
      "val_loss =  0.02961205850567333\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.007120234787621506\n",
      "val_loss =  0.02700256582092052\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.005309304286339469\n",
      "val_loss =  0.024566376935597267\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.00640280504799651\n",
      "val_loss =  0.02508304447459289\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.006536595403538293\n",
      "val_loss =  0.026161382150856602\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.00896656755660747\n",
      "val_loss =  0.02961205850567333\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.007120234787621506\n",
      "val_loss =  0.02700256582092052\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.005309304286339469\n",
      "val_loss =  0.024566376935597267\n",
      "+++++++++++++++++++++++++   22   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.020990119053086908\n",
      "val_loss =  0.029463924223600415\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.03024442177321178\n",
      "val_loss =  0.03031531868140189\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.028002832677661925\n",
      "val_loss =  0.03022161446526117\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.02954634817433616\n",
      "val_loss =  0.030272151115028414\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.02901688930219309\n",
      "val_loss =  0.0314120711264658\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.020990119053086908\n",
      "val_loss =  0.029463924223600415\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.03024442177321178\n",
      "val_loss =  0.03031531868140189\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.028002832677661925\n",
      "val_loss =  0.03022161446526117\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.02954634817433616\n",
      "val_loss =  0.030272151115028414\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.02901688930219309\n",
      "val_loss =  0.0314120711264658\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.020990119053086908\n",
      "val_loss =  0.029463924223600415\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.03024442177321178\n",
      "val_loss =  0.03031531868140189\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.028002832677661925\n",
      "val_loss =  0.03022161446526117\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.02954634817433616\n",
      "val_loss =  0.030272151115028414\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.02901688930219309\n",
      "val_loss =  0.0314120711264658\n",
      "+++++++++++++++++++++++++   23   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.03125410305456924\n",
      "val_loss =  0.04227612802942743\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02860381025793133\n",
      "val_loss =  0.04175023783030014\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.034835795362917386\n",
      "val_loss =  0.0431125191596497\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.03383090207786256\n",
      "val_loss =  0.043240863646916004\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.03681192879407357\n",
      "val_loss =  0.04297526490453223\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.03125410305456924\n",
      "val_loss =  0.04227612802942743\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02860381025793133\n",
      "val_loss =  0.04175023783030014\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.034835795362917386\n",
      "val_loss =  0.0431125191596497\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.03383090207786256\n",
      "val_loss =  0.043240863646916004\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.03681192879407357\n",
      "val_loss =  0.04297526490453223\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.03125410305456924\n",
      "val_loss =  0.04227612802942743\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02860381025793133\n",
      "val_loss =  0.04175023783030014\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.034835795362917386\n",
      "val_loss =  0.0431125191596497\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.03383090207786256\n",
      "val_loss =  0.043240863646916004\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.03681192879407357\n",
      "val_loss =  0.04297526490453223\n",
      "+++++++++++++++++++++++++   24   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.007801341746843882\n",
      "val_loss =  0.013820906113889598\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.008625010490928491\n",
      "val_loss =  0.01371072542661433\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0016326726609008544\n",
      "val_loss =  0.00976800070073551\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.010896322705362149\n",
      "val_loss =  0.023353318715870777\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.006227941367999803\n",
      "val_loss =  0.01501020630546927\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.007801341746843882\n",
      "val_loss =  0.013820906113889598\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.008625010490928491\n",
      "val_loss =  0.01371072542661433\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0016326726609008544\n",
      "val_loss =  0.00976800070073551\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.010896322705362149\n",
      "val_loss =  0.023353318715870777\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.006227941367999803\n",
      "val_loss =  0.01501020630546927\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.007801341746843882\n",
      "val_loss =  0.013820906113889598\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.008625010490928491\n",
      "val_loss =  0.01371072542661433\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0016326726609008544\n",
      "val_loss =  0.00976800070073551\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.010896322705362149\n",
      "val_loss =  0.023353318715870777\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.006227941367999803\n",
      "val_loss =  0.01501020630546927\n",
      "+++++++++++++++++++++++++   25   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.07084628611608831\n",
      "val_loss =  0.08214335533422928\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.07722486905280394\n",
      "val_loss =  0.08309802802594661\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.07733033305428119\n",
      "val_loss =  0.08374939467981538\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.07169050671911122\n",
      "val_loss =  0.08370873536693386\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.07675649162746619\n",
      "val_loss =  0.0827729904647917\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.07084628611608831\n",
      "val_loss =  0.08214335533422928\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.07722486905280394\n",
      "val_loss =  0.08309802802594661\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.07733033305428119\n",
      "val_loss =  0.08374939467981538\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.07169050671911122\n",
      "val_loss =  0.08370873536693386\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.07675649162746619\n",
      "val_loss =  0.0827729904647917\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.07084628611608831\n",
      "val_loss =  0.08214335533422928\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.07722486905280394\n",
      "val_loss =  0.08309802802594661\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.07733033305428119\n",
      "val_loss =  0.08374939467981538\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.07169050671911122\n",
      "val_loss =  0.08370873536693386\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.07675649162746619\n",
      "val_loss =  0.0827729904647917\n",
      "+++++++++++++++++++++++++   26   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.04985038702395965\n",
      "val_loss =  0.058585599973100866\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.0486258249343171\n",
      "val_loss =  0.05947974018816613\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05260275128890693\n",
      "val_loss =  0.05878829406454956\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05393487938348849\n",
      "val_loss =  0.05890261420771667\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04543176263549649\n",
      "val_loss =  0.05851326399300009\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.04985038702395965\n",
      "val_loss =  0.058585599973100866\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.0486258249343171\n",
      "val_loss =  0.05947974018816613\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05260275128890693\n",
      "val_loss =  0.05878829406454956\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05393487938348849\n",
      "val_loss =  0.05890261420771667\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04543176263549649\n",
      "val_loss =  0.05851326399300009\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.04985038702395965\n",
      "val_loss =  0.058585599973100866\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.0486258249343171\n",
      "val_loss =  0.05947974018816613\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05260275128890693\n",
      "val_loss =  0.05878829406454956\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05393487938348849\n",
      "val_loss =  0.05890261420771667\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04543176263549649\n",
      "val_loss =  0.05851326399300009\n",
      "+++++++++++++++++++++++++   27   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.022994522743470587\n",
      "val_loss =  0.0251464075661132\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.023178801189751783\n",
      "val_loss =  0.025251717446894115\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.022313327767940584\n",
      "val_loss =  0.025157068212172277\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.021132660042229905\n",
      "val_loss =  0.025152413133111704\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.021378487351748087\n",
      "val_loss =  0.02499841318220587\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.022994522743470587\n",
      "val_loss =  0.0251464075661132\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.023178801189751783\n",
      "val_loss =  0.025251717446894115\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.022313327767940584\n",
      "val_loss =  0.025157068212172277\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.021132660042229905\n",
      "val_loss =  0.025152413133111704\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.021378487351748087\n",
      "val_loss =  0.02499841318220587\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.022994522743470587\n",
      "val_loss =  0.0251464075661132\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.023178801189751783\n",
      "val_loss =  0.025251717446894115\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.022313327767940584\n",
      "val_loss =  0.025157068212172277\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.021132660042229905\n",
      "val_loss =  0.025152413133111704\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.021378487351748087\n",
      "val_loss =  0.02499841318220587\n",
      "+++++++++++++++++++++++++   28   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02676375084000363\n",
      "val_loss =  0.03621381029849721\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.021681270814668172\n",
      "val_loss =  0.03359685721028212\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.020854607121997843\n",
      "val_loss =  0.033963511781215115\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.023329225035859366\n",
      "val_loss =  0.03425760796427056\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01924663572618747\n",
      "val_loss =  0.031900470986631554\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02676375084000363\n",
      "val_loss =  0.03621381029849721\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.021681270814668172\n",
      "val_loss =  0.03359685721028212\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.020854607121997843\n",
      "val_loss =  0.033963511781215115\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.023329225035859366\n",
      "val_loss =  0.03425760796427056\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01924663572618747\n",
      "val_loss =  0.031900470986631554\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02676375084000363\n",
      "val_loss =  0.03621381029849721\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.021681270814668172\n",
      "val_loss =  0.03359685721028212\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.020854607121997843\n",
      "val_loss =  0.033963511781215115\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.023329225035859366\n",
      "val_loss =  0.03425760796427056\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01924663572618747\n",
      "val_loss =  0.031900470986631554\n",
      "+++++++++++++++++++++++++   29   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02794560108882105\n",
      "val_loss =  0.027857153514324974\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.016932429100378385\n",
      "val_loss =  0.026646617040198065\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.021814393454650235\n",
      "val_loss =  0.027431129063835134\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.026485489109356067\n",
      "val_loss =  0.02773366967017494\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.025761122988095103\n",
      "val_loss =  0.028997000868213312\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02794560108882105\n",
      "val_loss =  0.027857153514324974\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.016932429100378385\n",
      "val_loss =  0.026646617040198065\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.021814393454650235\n",
      "val_loss =  0.027431129063835134\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.026485489109356067\n",
      "val_loss =  0.02773366967017494\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.025761122988095103\n",
      "val_loss =  0.028997000868213312\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.02794560108882105\n",
      "val_loss =  0.027857153514324974\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.016932429100378385\n",
      "val_loss =  0.026646617040198065\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.021814393454650235\n",
      "val_loss =  0.027431129063835134\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.026485489109356067\n",
      "val_loss =  0.02773366967017494\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.025761122988095103\n",
      "val_loss =  0.028997000868213312\n",
      "+++++++++++++++++++++++++   30   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.005936000731347418\n",
      "val_loss =  0.01801867540060702\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.006924813173371426\n",
      "val_loss =  0.020443868798314\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.006247087080800742\n",
      "val_loss =  0.021618005574409762\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.007448160630050233\n",
      "val_loss =  0.027587583559359204\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.005482233006727402\n",
      "val_loss =  0.02216019372346792\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.005936000731347418\n",
      "val_loss =  0.01801867540060702\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.006924813173371426\n",
      "val_loss =  0.020443868798314\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.006247087080800742\n",
      "val_loss =  0.021618005574409762\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.007448160630050233\n",
      "val_loss =  0.027587583559359204\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.005482233006727402\n",
      "val_loss =  0.02216019372346792\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.005936000731347418\n",
      "val_loss =  0.01801867540060702\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.006924813173371426\n",
      "val_loss =  0.020443868798314\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.006247087080800742\n",
      "val_loss =  0.021618005574409762\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.007448160630050233\n",
      "val_loss =  0.027587583559359204\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.005482233006727402\n",
      "val_loss =  0.02216019372346792\n",
      "+++++++++++++++++++++++++   31   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.041842797123644825\n",
      "val_loss =  0.06210278790237842\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05448851326672577\n",
      "val_loss =  0.06369355040681302\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05712527926246168\n",
      "val_loss =  0.06410172402016585\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05063183741552304\n",
      "val_loss =  0.06295089965852577\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04917699664625793\n",
      "val_loss =  0.06188558199286395\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.041842797123644825\n",
      "val_loss =  0.06210278790237842\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05448851326672577\n",
      "val_loss =  0.06369355040681302\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05712527926246168\n",
      "val_loss =  0.06410172402016585\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05063183741552304\n",
      "val_loss =  0.06295089965852577\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04917699664625793\n",
      "val_loss =  0.06188558199286395\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.041842797123644825\n",
      "val_loss =  0.06210278790237842\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05448851326672577\n",
      "val_loss =  0.06369355040681302\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05712527926246168\n",
      "val_loss =  0.06410172402016585\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05063183741552304\n",
      "val_loss =  0.06295089965852577\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.04917699664625793\n",
      "val_loss =  0.06188558199286395\n",
      "+++++++++++++++++++++++++   32   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.009755673081285979\n",
      "val_loss =  0.026680091900221976\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.008173475995725191\n",
      "val_loss =  0.026857342246558856\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.016139379701908426\n",
      "val_loss =  0.03318576606350289\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.017516233648867018\n",
      "val_loss =  0.03256873727812853\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.010138645068434147\n",
      "val_loss =  0.023821546294668965\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.009755673081285979\n",
      "val_loss =  0.026680091900221976\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.008173475995725191\n",
      "val_loss =  0.026857342246558856\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.016139379701908426\n",
      "val_loss =  0.03318576606350289\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.017516233648867018\n",
      "val_loss =  0.03256873727812853\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.010138645068434147\n",
      "val_loss =  0.023821546294668965\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.009755673081285979\n",
      "val_loss =  0.026680091900221976\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.008173475995725191\n",
      "val_loss =  0.026857342246558856\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.016139379701908426\n",
      "val_loss =  0.03318576606350289\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.017516233648867018\n",
      "val_loss =  0.03256873727812853\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.010138645068434147\n",
      "val_loss =  0.023821546294668965\n",
      "+++++++++++++++++++++++++   33   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.026614211885703846\n",
      "val_loss =  0.02768630849217986\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.019939411365802837\n",
      "val_loss =  0.027199271685276083\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.013027389467550938\n",
      "val_loss =  0.0267246051832648\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.026784608364806273\n",
      "val_loss =  0.028902497088978213\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.025578792070195436\n",
      "val_loss =  0.028764718450998785\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.026614211885703846\n",
      "val_loss =  0.02768630849217986\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.019939411365802837\n",
      "val_loss =  0.027199271685276083\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.013027389467550938\n",
      "val_loss =  0.0267246051832648\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.026784608364806273\n",
      "val_loss =  0.028902497088978213\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.025578792070195436\n",
      "val_loss =  0.028764718450998785\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.026614211885703846\n",
      "val_loss =  0.02768630849217986\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.019939411365802837\n",
      "val_loss =  0.027199271685276083\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.013027389467550938\n",
      "val_loss =  0.0267246051832648\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.026784608364806273\n",
      "val_loss =  0.028902497088978213\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.025578792070195436\n",
      "val_loss =  0.028764718450998785\n",
      "+++++++++++++++++++++++++   34   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.011638263365398017\n",
      "val_loss =  0.027834717845363878\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.017539362097549128\n",
      "val_loss =  0.028928771200785717\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.018807863428212807\n",
      "val_loss =  0.024551451021308037\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.01331100624675304\n",
      "val_loss =  0.02639830479154385\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.013041763508614702\n",
      "val_loss =  0.024014698487842594\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.011638263365398017\n",
      "val_loss =  0.027834717845363878\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.017539362097549128\n",
      "val_loss =  0.028928771200785717\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.018807863428212807\n",
      "val_loss =  0.024551451021308037\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.01331100624675304\n",
      "val_loss =  0.02639830479154385\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.013041763508614702\n",
      "val_loss =  0.024014698487842594\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.011638263365398017\n",
      "val_loss =  0.027834717845363878\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.017539362097549128\n",
      "val_loss =  0.028928771200785717\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.018807863428212807\n",
      "val_loss =  0.024551451021308037\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.01331100624675304\n",
      "val_loss =  0.02639830479154385\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.013041763508614702\n",
      "val_loss =  0.024014698487842594\n",
      "+++++++++++++++++++++++++   35   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01610651862058426\n",
      "val_loss =  0.03066016434667029\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02417226866141997\n",
      "val_loss =  0.03154567664526824\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.018121072938421235\n",
      "val_loss =  0.03190951716912427\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.020029643942088216\n",
      "val_loss =  0.03158543792972016\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01156879625580027\n",
      "val_loss =  0.029029687363999676\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01610651862058426\n",
      "val_loss =  0.03066016434667029\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02417226866141997\n",
      "val_loss =  0.03154567664526824\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.018121072938421235\n",
      "val_loss =  0.03190951716912427\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.020029643942088216\n",
      "val_loss =  0.03158543792972016\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01156879625580027\n",
      "val_loss =  0.029029687363999676\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01610651862058426\n",
      "val_loss =  0.03066016434667029\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.02417226866141997\n",
      "val_loss =  0.03154567664526824\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.018121072938421235\n",
      "val_loss =  0.03190951716912427\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.020029643942088216\n",
      "val_loss =  0.03158543792972016\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01156879625580027\n",
      "val_loss =  0.029029687363999676\n",
      "+++++++++++++++++++++++++   36   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.020736464483753547\n",
      "val_loss =  0.025002585351362846\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.023179242395342047\n",
      "val_loss =  0.025231822207080513\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.02531253412170477\n",
      "val_loss =  0.024110125713637236\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.022493360254792334\n",
      "val_loss =  0.025034337423082854\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.018459274045964043\n",
      "val_loss =  0.024413468608838796\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.020736464483753547\n",
      "val_loss =  0.025002585351362846\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.023179242395342047\n",
      "val_loss =  0.025231822207080513\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.02531253412170477\n",
      "val_loss =  0.024110125713637236\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.022493360254792334\n",
      "val_loss =  0.025034337423082854\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.018459274045964043\n",
      "val_loss =  0.024413468608838796\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.020736464483753547\n",
      "val_loss =  0.025002585351362846\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.023179242395342047\n",
      "val_loss =  0.025231822207080513\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.02531253412170477\n",
      "val_loss =  0.024110125713637236\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.022493360254792334\n",
      "val_loss =  0.025034337423082854\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.018459274045964043\n",
      "val_loss =  0.024413468608838796\n",
      "+++++++++++++++++++++++++   37   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.010525302213371633\n",
      "val_loss =  0.023721757049730934\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.016364466154586907\n",
      "val_loss =  0.024250857131707493\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.016200490699600195\n",
      "val_loss =  0.025535072482995455\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.012020166944467859\n",
      "val_loss =  0.025146566389066035\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.011742228760595703\n",
      "val_loss =  0.02235257800658987\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.010525302213371633\n",
      "val_loss =  0.023721757049730934\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.016364466154586907\n",
      "val_loss =  0.024250857131707493\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.016200490699600195\n",
      "val_loss =  0.025535072482995455\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.012020166944467859\n",
      "val_loss =  0.025146566389066035\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.011742228760595703\n",
      "val_loss =  0.02235257800658987\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.010525302213371633\n",
      "val_loss =  0.023721757049730934\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.016364466154586907\n",
      "val_loss =  0.024250857131707493\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.016200490699600195\n",
      "val_loss =  0.025535072482995455\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.012020166944467859\n",
      "val_loss =  0.025146566389066035\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.011742228760595703\n",
      "val_loss =  0.02235257800658987\n",
      "+++++++++++++++++++++++++   38   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.052820587170342256\n",
      "val_loss =  0.058406943835975604\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05357250166547696\n",
      "val_loss =  0.059514099509281444\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05119958002112095\n",
      "val_loss =  0.057737658090258985\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05315178445551491\n",
      "val_loss =  0.05817845229620665\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.049171923174001604\n",
      "val_loss =  0.05766863638695276\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.052820587170342256\n",
      "val_loss =  0.058406943835975604\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05357250166547696\n",
      "val_loss =  0.059514099509281444\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05119958002112095\n",
      "val_loss =  0.057737658090258985\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05315178445551491\n",
      "val_loss =  0.05817845229620665\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.049171923174001604\n",
      "val_loss =  0.05766863638695276\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.052820587170342256\n",
      "val_loss =  0.058406943835975604\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05357250166547696\n",
      "val_loss =  0.059514099509281444\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.05119958002112095\n",
      "val_loss =  0.057737658090258985\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.05315178445551491\n",
      "val_loss =  0.05817845229620665\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.049171923174001604\n",
      "val_loss =  0.05766863638695276\n",
      "+++++++++++++++++++++++++   39   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.07620959764167072\n",
      "val_loss =  0.08734772588566055\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.07081304635557932\n",
      "val_loss =  0.08669472030908669\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.069444367459953\n",
      "val_loss =  0.08681093726196933\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.07042592814173929\n",
      "val_loss =  0.08723128395264794\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.06966935596481706\n",
      "val_loss =  0.08699818404598927\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.07620959764167072\n",
      "val_loss =  0.08734772588566055\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.07081304635557932\n",
      "val_loss =  0.08669472030908669\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.069444367459953\n",
      "val_loss =  0.08681093726196933\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.07042592814173929\n",
      "val_loss =  0.08723128395264794\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.06966935596481706\n",
      "val_loss =  0.08699818404598927\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.07620959764167072\n",
      "val_loss =  0.08734772588566055\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.07081304635557932\n",
      "val_loss =  0.08669472030908669\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.069444367459953\n",
      "val_loss =  0.08681093726196933\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.07042592814173929\n",
      "val_loss =  0.08723128395264794\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.06966935596481706\n",
      "val_loss =  0.08699818404598927\n",
      "+++++++++++++++++++++++++   40   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.06104002881073146\n",
      "val_loss =  0.0647642391837971\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05909849578632373\n",
      "val_loss =  0.0653432981783348\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0615160490176869\n",
      "val_loss =  0.06451444817109776\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.057020440438778984\n",
      "val_loss =  0.0652051666214234\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.06257896246963175\n",
      "val_loss =  0.06487155035445297\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.06104002881073146\n",
      "val_loss =  0.0647642391837971\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05909849578632373\n",
      "val_loss =  0.0653432981783348\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0615160490176869\n",
      "val_loss =  0.06451444817109776\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.057020440438778984\n",
      "val_loss =  0.0652051666214234\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.06257896246963175\n",
      "val_loss =  0.06487155035445297\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.06104002881073146\n",
      "val_loss =  0.0647642391837971\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.05909849578632373\n",
      "val_loss =  0.0653432981783348\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.0615160490176869\n",
      "val_loss =  0.06451444817109776\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.057020440438778984\n",
      "val_loss =  0.0652051666214234\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.06257896246963175\n",
      "val_loss =  0.06487155035445297\n",
      "+++++++++++++++++++++++++   41   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.009113116589174481\n",
      "val_loss =  0.023218989241907812\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.008466957257606352\n",
      "val_loss =  0.027891470344449044\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.007126875549940811\n",
      "val_loss =  0.020190988513530763\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.006060370309605915\n",
      "val_loss =  0.020462063365854866\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.00674571282484742\n",
      "val_loss =  0.02235492569796867\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.009113116589174481\n",
      "val_loss =  0.023218989241907812\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.008466957257606352\n",
      "val_loss =  0.027891470344449044\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.007126875549940811\n",
      "val_loss =  0.020190988513530763\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.006060370309605915\n",
      "val_loss =  0.020462063365854866\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.00674571282484742\n",
      "val_loss =  0.02235492569796867\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.009113116589174481\n",
      "val_loss =  0.023218989241907812\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.008466957257606352\n",
      "val_loss =  0.027891470344449044\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.007126875549940811\n",
      "val_loss =  0.020190988513530763\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.006060370309605915\n",
      "val_loss =  0.020462063365854866\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.00674571282484742\n",
      "val_loss =  0.02235492569796867\n",
      "+++++++++++++++++++++++++   42   +++++++++++++++++++++++++\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01112267527299556\n",
      "val_loss =  0.02795292865366409\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.013068955690342644\n",
      "val_loss =  0.030917477202562833\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.013709166007117163\n",
      "val_loss =  0.025950388488573596\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.008207252035709484\n",
      "val_loss =  0.02339671323372772\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01488923786951808\n",
      "val_loss =  0.03001741690375838\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01112267527299556\n",
      "val_loss =  0.02795292865366409\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.013068955690342644\n",
      "val_loss =  0.030917477202562833\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.013709166007117163\n",
      "val_loss =  0.025950388488573596\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.008207252035709484\n",
      "val_loss =  0.02339671323372772\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01488923786951808\n",
      "val_loss =  0.03001741690375838\n",
      "_________________________ seed -------------------------\n",
      "*************************   0   *************************\n",
      "Params 2\n",
      "loss =  0.01112267527299556\n",
      "val_loss =  0.02795292865366409\n",
      "*************************   1   *************************\n",
      "Params 2\n",
      "loss =  0.013068955690342644\n",
      "val_loss =  0.030917477202562833\n",
      "*************************   2   *************************\n",
      "Params 2\n",
      "loss =  0.013709166007117163\n",
      "val_loss =  0.025950388488573596\n",
      "*************************   3   *************************\n",
      "Params 2\n",
      "loss =  0.008207252035709484\n",
      "val_loss =  0.02339671323372772\n",
      "*************************   4   *************************\n",
      "Params 2\n",
      "loss =  0.01488923786951808\n",
      "val_loss =  0.03001741690375838\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "\n",
    "SEED = [1903, 1881, 1589]\n",
    "oof = np.zeros((len(train), len(s)))\n",
    "predictions = np.zeros((len(test), len(s)))\n",
    "for m, col in enumerate(s):\n",
    "    print('+'*25,' ',m,' ','+'*25)\n",
    "    for seed in SEED:\n",
    "        print('_'*25,'seed','-'*25)\n",
    "        oof_, predictions_ = run_k_fold_lgbm(NFOLDS, seed, col)\n",
    "        oof[:,m] += oof_ / len(SEED)\n",
    "        predictions[:,m] += predictions_ / len(SEED)\n",
    "\n",
    "train[s] = oof\n",
    "test[s] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T01:23:27.782157Z",
     "iopub.status.busy": "2020-11-11T01:23:27.780795Z",
     "iopub.status.idle": "2020-11-11T01:23:28.755239Z",
     "shell.execute_reply": "2020-11-11T01:23:28.754226Z"
    },
    "papermill": {
     "duration": 1.930125,
     "end_time": "2020-11-11T01:23:28.755395",
     "exception": false,
     "start_time": "2020-11-11T01:23:26.825270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV log_loss after LGBM:  0.015275807169971782\n"
     ]
    }
   ],
   "source": [
    "valid_results = train_targets_scored.drop(columns=target_cols).merge(train[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "\n",
    "\n",
    "y_true = train_targets_scored[target_cols].values\n",
    "y_pred = valid_results[target_cols].values\n",
    "\n",
    "score = 0\n",
    "scores = []\n",
    "for i in range(len(target_cols)):\n",
    "    score_ = log_loss(y_true[:, i], y_pred[:, i])\n",
    "    score += score_ / 206\n",
    "    scores += [score_]\n",
    "print(\"CV log_loss after LGBM: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.09708,
     "end_time": "2020-11-11T01:23:30.799810",
     "exception": false,
     "start_time": "2020-11-11T01:23:29.702730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T01:23:33.155884Z",
     "iopub.status.busy": "2020-11-11T01:23:33.153380Z",
     "iopub.status.idle": "2020-11-11T01:23:35.276956Z",
     "shell.execute_reply": "2020-11-11T01:23:35.275862Z"
    },
    "papermill": {
     "duration": 3.413163,
     "end_time": "2020-11-11T01:23:35.277077",
     "exception": false,
     "start_time": "2020-11-11T01:23:31.863914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T01:23:37.163806Z",
     "iopub.status.busy": "2020-11-11T01:23:37.162947Z",
     "iopub.status.idle": "2020-11-11T01:23:37.168922Z",
     "shell.execute_reply": "2020-11-11T01:23:37.168443Z"
    },
    "papermill": {
     "duration": 0.965858,
     "end_time": "2020-11-11T01:23:37.169046",
     "exception": false,
     "start_time": "2020-11-11T01:23:36.203188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3982, 207)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 20763.622924,
   "end_time": "2020-11-11T01:23:39.160133",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-10T19:37:35.537209",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
